{
    "docs": [
        {
            "location": "/", 
            "text": "DataFrames Documentation Outline\n\n\n\n\nPackage Manual\n\n\n\n\nGetting Started\n\n\nInstallation\n\n\nThe \nNA\n Value\n\n\nThe \nDataArray\n Type\n\n\nThe \nDataFrame\n Type\n\n\nAccessing Classic Data Sets\n\n\n\n\n\n\nImporting and Exporting (I/O)\n\n\nImporting data from tabular data files\n\n\nExporting data to a tabular data file\n\n\nSupplying \nDataFrame\ns inline with non-standard string literals\n\n\n\n\n\n\nDatabase-Style Joins\n\n\nThe Split-Apply-Combine Strategy\n\n\nReshaping and Pivoting Data\n\n\nSorting\n\n\nThe Formula, ModelFrame and ModelMatrix Types\n\n\nPooling Data (Representing Factors)\n\n\n\n\n\n\nAPI\n\n\n\n\nMain Types\n\n\nData Manipulation\n\n\nJoins\n\n\nReshaping\n\n\n\n\n\n\nUtilities\n\n\n\n\n\n\nDocumentation Index\n\n\n\n\nAbstractDataFrame\n\n\nDataFrame\n\n\nSubDataFrame\n\n\njoin\n\n\nmelt\n\n\nmeltdf\n\n\nstack\n\n\nstackdf\n\n\nunstack\n\n\ndump\n\n\nunique\n\n\nhead\n\n\ntail\n\n\ncomplete_cases\n\n\ncomplete_cases!\n\n\neltypes\n\n\nnames!\n\n\nnonunique\n\n\nrename\n\n\nrename!\n\n\nunique!\n\n\ndescribe\n\n\nreadtable\n\n\nwritetable", 
            "title": "Introduction"
        }, 
        {
            "location": "/#dataframes-documentation-outline", 
            "text": "", 
            "title": "DataFrames Documentation Outline"
        }, 
        {
            "location": "/#package-manual", 
            "text": "Getting Started  Installation  The  NA  Value  The  DataArray  Type  The  DataFrame  Type  Accessing Classic Data Sets    Importing and Exporting (I/O)  Importing data from tabular data files  Exporting data to a tabular data file  Supplying  DataFrame s inline with non-standard string literals    Database-Style Joins  The Split-Apply-Combine Strategy  Reshaping and Pivoting Data  Sorting  The Formula, ModelFrame and ModelMatrix Types  Pooling Data (Representing Factors)", 
            "title": "Package Manual"
        }, 
        {
            "location": "/#api", 
            "text": "Main Types  Data Manipulation  Joins  Reshaping    Utilities", 
            "title": "API"
        }, 
        {
            "location": "/#documentation-index", 
            "text": "AbstractDataFrame  DataFrame  SubDataFrame  join  melt  meltdf  stack  stackdf  unstack  dump  unique  head  tail  complete_cases  complete_cases!  eltypes  names!  nonunique  rename  rename!  unique!  describe  readtable  writetable", 
            "title": "Documentation Index"
        }, 
        {
            "location": "/man/getting_started/", 
            "text": "Getting Started\n\n\n\n\nInstallation\n\n\nThe DataFrames package is available through the Julia package system. Throughout the rest of this tutorial, we will assume that you have installed the DataFrames package and have already typed \nusing DataArrays, DataFrames\n to bring all of the relevant variables into your current namespace. In addition, we will make use of the \nRDatasets\n package, which provides access to hundreds of classical data sets.\n\n\n\n\nThe \nNA\n Value\n\n\nTo get started, let's examine the \nNA\n value. Type the following into the REPL:\n\n\nNA\n\n\n\n\n\n\nOne of the essential properties of \nNA\n is that it poisons other items. To see this, try to add something like \n1\n to \nNA\n:\n\n\n1\n \n+\n \nNA\n\n\n\n\n\n\n\n\nThe \nDataArray\n Type\n\n\nNow that we see that \nNA\n is working, let's insert one into a \nDataArray\n. We'll create one now using the \n@data\n macro:\n\n\ndv\n \n=\n \n@\ndata\n([\nNA\n,\n \n3\n,\n \n2\n,\n \n5\n,\n \n4\n])\n\n\n\n\n\n\nTo see how \nNA\n poisons even complex calculations, let's try to take the mean of the five numbers stored in \ndv\n:\n\n\nmean\n(\ndv\n)\n\n\n\n\n\n\nIn many cases we're willing to just ignore \nNA\n values and remove them from our vector. We can do that using the \ndropna\n function:\n\n\ndropna\n(\ndv\n)\n\n\nmean\n(\ndropna\n(\ndv\n))\n\n\n\n\n\n\nInstead of removing \nNA\n values, you can try to conver the \nDataArray\n into a normal Julia \nArray\n using \nconvert\n:\n\n\nconvert\n(\nArray\n,\n \ndv\n)\n\n\n\n\n\n\nThis fails in the presence of \nNA\n values, but will succeed if there are no \nNA\n values:\n\n\ndv\n[\n1\n]\n \n=\n \n3\n\n\nconvert\n(\nArray\n,\n \ndv\n)\n\n\n\n\n\n\nIn addition to removing \nNA\n values and hoping they won't occur, you can also replace any \nNA\n values using the \nconvert\n function, which takes a replacement value as an argument:\n\n\ndv\n \n=\n \n@\ndata\n([\nNA\n,\n \n3\n,\n \n2\n,\n \n5\n,\n \n4\n])\n\n\nmean\n(\nconvert\n(\nArray\n,\n \ndv\n,\n \n11\n))\n\n\n\n\n\n\nWhich strategy for dealing with \nNA\n values is most appropriate will typically depend on the specific details of your data analysis pathway.\n\n\nAlthough the examples above employed only 1D \nDataArray\n objects, the \nDataArray\n type defines a completely generic N-dimensional array type. Operations on generic \nDataArray\n objects work in higher dimensions in the same way that they work on Julia's Base \nArray\n type:\n\n\ndm\n \n=\n \n@\ndata\n([\nNA\n \n0.0\n;\n \n0.0\n \n1.0\n])\n\n\ndm\n \n*\n \ndm\n\n\n\n\n\n\n\n\nThe \nDataFrame\n Type\n\n\nThe \nDataFrame\n type can be used to represent data tables, each column of which is a \nDataArray\n. You can specify the columns using keyword arguments:\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n4\n,\n \nB\n \n=\n \n[\nM\n,\n \nF\n,\n \nF\n,\n \nM\n])\n\n\n\n\n\n\nIt is also possible to construct a \nDataFrame\n in stages:\n\n\ndf\n \n=\n \nDataFrame\n()\n\n\ndf\n[:\nA\n]\n \n=\n \n1\n:\n8\n\n\ndf\n[:\nB\n]\n \n=\n \n[\nM\n,\n \nF\n,\n \nF\n,\n \nM\n,\n \nF\n,\n \nM\n,\n \nM\n,\n \nF\n]\n\n\ndf\n\n\n\n\n\n\nThe \nDataFrame\n we build in this way has 8 rows and 2 columns. You can check this using \nsize\n function:\n\n\nnrows\n \n=\n \nsize\n(\ndf\n,\n \n1\n)\n\n\nncols\n \n=\n \nsize\n(\ndf\n,\n \n2\n)\n\n\n\n\n\n\nWe can also look at small subsets of the data in a couple of different ways:\n\n\nhead\n(\ndf\n)\n\n\ntail\n(\ndf\n)\n\n\n\ndf\n[\n1\n:\n3\n,\n \n:]\n\n\n\n\n\n\nHaving seen what some of the rows look like, we can try to summarize the entire data set using \ndescribe\n:\n\n\ndescribe\n(\ndf\n)\n\n\n\n\n\n\nTo focus our search, we start looking at just the means and medians of specific columns. In the example below, we use numeric indexing to access the columns of the \nDataFrame\n:\n\n\nmean\n(\ndf\n[\n1\n])\n\n\nmedian\n(\ndf\n[\n1\n])\n\n\n\n\n\n\nWe could also have used column names to access individual columns:\n\n\nmean\n(\ndf\n[:\nA\n])\n\n\nmedian\n(\ndf\n[:\nA\n])\n\n\n\n\n\n\nWe can also apply a function to each column of a \nDataFrame\n with the \ncolwise\n function. For example:\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n4\n,\n \nB\n \n=\n \nrandn\n(\n4\n))\n\n\ncolwise\n(\ncumsum\n,\n \ndf\n)\n\n\n\n\n\n\n\n\nAccessing Classic Data Sets\n\n\nTo see more of the functionality for working with \nDataFrame\n objects, we need a more complex data set to work with. We'll use the \nRDatasets\n package, which provides access to many of the classical data sets that are available in R.\n\n\nFor example, we can access Fisher's iris data set using the following functions:\n\n\nusing\n \nRDatasets\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\nhead\n(\niris\n)\n\n\n\n\n\n\nIn the next section, we'll discuss generic I/O strategy for reading and writing \nDataFrame\n objects that you can use to import and export your own data files.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/man/getting_started/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/man/getting_started/#installation", 
            "text": "The DataFrames package is available through the Julia package system. Throughout the rest of this tutorial, we will assume that you have installed the DataFrames package and have already typed  using DataArrays, DataFrames  to bring all of the relevant variables into your current namespace. In addition, we will make use of the  RDatasets  package, which provides access to hundreds of classical data sets.", 
            "title": "Installation"
        }, 
        {
            "location": "/man/getting_started/#the-na-value", 
            "text": "To get started, let's examine the  NA  value. Type the following into the REPL:  NA   One of the essential properties of  NA  is that it poisons other items. To see this, try to add something like  1  to  NA :  1   +   NA", 
            "title": "The NA Value"
        }, 
        {
            "location": "/man/getting_started/#the-dataarray-type", 
            "text": "Now that we see that  NA  is working, let's insert one into a  DataArray . We'll create one now using the  @data  macro:  dv   =   @ data ([ NA ,   3 ,   2 ,   5 ,   4 ])   To see how  NA  poisons even complex calculations, let's try to take the mean of the five numbers stored in  dv :  mean ( dv )   In many cases we're willing to just ignore  NA  values and remove them from our vector. We can do that using the  dropna  function:  dropna ( dv )  mean ( dropna ( dv ))   Instead of removing  NA  values, you can try to conver the  DataArray  into a normal Julia  Array  using  convert :  convert ( Array ,   dv )   This fails in the presence of  NA  values, but will succeed if there are no  NA  values:  dv [ 1 ]   =   3  convert ( Array ,   dv )   In addition to removing  NA  values and hoping they won't occur, you can also replace any  NA  values using the  convert  function, which takes a replacement value as an argument:  dv   =   @ data ([ NA ,   3 ,   2 ,   5 ,   4 ])  mean ( convert ( Array ,   dv ,   11 ))   Which strategy for dealing with  NA  values is most appropriate will typically depend on the specific details of your data analysis pathway.  Although the examples above employed only 1D  DataArray  objects, the  DataArray  type defines a completely generic N-dimensional array type. Operations on generic  DataArray  objects work in higher dimensions in the same way that they work on Julia's Base  Array  type:  dm   =   @ data ([ NA   0.0 ;   0.0   1.0 ])  dm   *   dm", 
            "title": "The DataArray Type"
        }, 
        {
            "location": "/man/getting_started/#the-dataframe-type", 
            "text": "The  DataFrame  type can be used to represent data tables, each column of which is a  DataArray . You can specify the columns using keyword arguments:  df   =   DataFrame ( A   =   1 : 4 ,   B   =   [ M ,   F ,   F ,   M ])   It is also possible to construct a  DataFrame  in stages:  df   =   DataFrame ()  df [: A ]   =   1 : 8  df [: B ]   =   [ M ,   F ,   F ,   M ,   F ,   M ,   M ,   F ]  df   The  DataFrame  we build in this way has 8 rows and 2 columns. You can check this using  size  function:  nrows   =   size ( df ,   1 )  ncols   =   size ( df ,   2 )   We can also look at small subsets of the data in a couple of different ways:  head ( df )  tail ( df )  df [ 1 : 3 ,   :]   Having seen what some of the rows look like, we can try to summarize the entire data set using  describe :  describe ( df )   To focus our search, we start looking at just the means and medians of specific columns. In the example below, we use numeric indexing to access the columns of the  DataFrame :  mean ( df [ 1 ])  median ( df [ 1 ])   We could also have used column names to access individual columns:  mean ( df [: A ])  median ( df [: A ])   We can also apply a function to each column of a  DataFrame  with the  colwise  function. For example:  df   =   DataFrame ( A   =   1 : 4 ,   B   =   randn ( 4 ))  colwise ( cumsum ,   df )", 
            "title": "The DataFrame Type"
        }, 
        {
            "location": "/man/getting_started/#accessing-classic-data-sets", 
            "text": "To see more of the functionality for working with  DataFrame  objects, we need a more complex data set to work with. We'll use the  RDatasets  package, which provides access to many of the classical data sets that are available in R.  For example, we can access Fisher's iris data set using the following functions:  using   RDatasets  iris   =   dataset ( datasets ,   iris )  head ( iris )   In the next section, we'll discuss generic I/O strategy for reading and writing  DataFrame  objects that you can use to import and export your own data files.", 
            "title": "Accessing Classic Data Sets"
        }, 
        {
            "location": "/man/io/", 
            "text": "Importing and Exporting (I/O)\n\n\n\n\nImporting data from tabular data files\n\n\nTo read data from a CSV-like file, use the \nreadtable\n function:\n\n\n#\nDataFrames.readtable\n \n \nFunction\n.\n\n\n\n\nRead data from a tabular-file format (CSV, TSV, ...)\n\n\nreadtable\n(\nfilename\n;\n\n          \nheader\n::\nBool\n \n=\n \ntrue\n,\n\n          \nseparator\n::\nChar\n \n=\n \ngetseparator\n(\npathname\n),\n\n          \nquotemark\n::\nVector\n{\nChar\n}\n \n=\n \n[\n],\n\n          \ndecimal\n::\nChar\n \n=\n \n.\n,\n\n          \nnastrings\n::\nVector\n \n=\n \nASCIIString\n[\n,\n \nNA\n],\n\n          \ntruestrings\n::\nVector\n \n=\n \nASCIIString\n[\nT\n,\n \nt\n,\n \nTRUE\n,\n \ntrue\n],\n\n          \nfalsestrings\n::\nVector\n \n=\n \nASCIIString\n[\nF\n,\n \nf\n,\n \nFALSE\n,\n \nfalse\n],\n\n          \nmakefactors\n::\nBool\n \n=\n \nfalse\n,\n\n          \nnrows\n::\nInteger\n \n=\n \n-\n1\n,\n\n          \nnames\n::\nVector\n \n=\n \nSymbol\n[],\n\n          \neltypes\n::\nVector\n{\nDataType\n}\n \n=\n \nDataType\n[],\n\n          \nallowcomments\n::\nBool\n \n=\n \nfalse\n,\n\n          \ncommentmark\n::\nChar\n \n=\n \n#\n,\n\n          \nignorepadding\n::\nBool\n \n=\n \ntrue\n,\n\n          \nskipstart\n::\nInteger\n \n=\n \n0\n,\n\n          \nskiprows\n::\nAbstractVector\n{\nInt\n}\n \n=\n \nInt\n[],\n\n          \nskipblanks\n::\nBool\n \n=\n \ntrue\n,\n\n          \nencoding\n::\nSymbol\n \n=\n \n:\nutf8\n,\n\n          \nallowescapes\n::\nBool\n \n=\n \nfalse\n,\n\n          \nnormalizenames\n::\nBool\n \n=\n \ntrue\n)\n\n\n\n\n\n\nArguments\n\n\n\n\nfilename\n : the filename to be read\n\n\n\n\nKeyword Arguments\n\n\n\n\nheader::Bool\n \u2013 Use the information from the file's header line to determine column names. Defaults to \ntrue\n.\n\n\nseparator::Char\n \u2013 Assume that fields are split by the \nseparator\n character. If not specified, it will be guessed from the filename: \n.csv\n defaults to \n','\n, \n.tsv\n defaults to \n'    '\n, \n.wsv\n defaults to \n' '\n.\n\n\nquotemark::Vector{Char}\n \u2013 Assume that fields contained inside of two \nquotemark\n characters are quoted, which disables processing of separators and linebreaks. Set to \nChar[]\n to disable this feature and slightly improve performance. Defaults to \n['\"']\n.\n\n\ndecimal::Char\n \u2013 Assume that the decimal place in numbers is written using the \ndecimal\n character. Defaults to \n'.'\n.\n\n\nnastrings::Vector{ASCIIString}\n \u2013 Translate any of the strings into this vector into an \nNA\n. Defaults to \n[\"\", \"NA\"]\n.\n\n\ntruestrings::Vector{ASCIIString}\n \u2013 Translate any of the strings into this vector into a Boolean \ntrue\n. Defaults to \n[\"T\", \"t\", \"TRUE\", \"true\"]\n.\n\n\nfalsestrings::Vector{ASCIIString}\n \u2013 Translate any of the strings into this vector into a Boolean \nfalse\n. Defaults to \n[\"F\", \"f\", \"FALSE\", \"false\"]\n.\n\n\nmakefactors::Bool\n \u2013 Convert string columns into \nPooledDataVector\n's for use as factors. Defaults to \nfalse\n.\n\n\nnrows::Int\n \u2013 Read only \nnrows\n from the file. Defaults to \n-1\n, which indicates that the entire file should be read.\n\n\nnames::Vector{Symbol}\n \u2013 Use the values in this array as the names for all columns instead of or in lieu of the names in the file's header. Defaults to \n[]\n, which indicates that the header should be used if present or that numeric names should be invented if there is no header.\n\n\neltypes::Vector{DataType}\n \u2013 Specify the types of all columns. Defaults to \n[]\n.\n\n\nallowcomments::Bool\n \u2013 Ignore all text inside comments. Defaults to \nfalse\n.\n\n\ncommentmark::Char\n \u2013 Specify the character that starts comments. Defaults to \n'#'\n.\n\n\nignorepadding::Bool\n \u2013 Ignore all whitespace on left and right sides of a field. Defaults to \ntrue\n.\n\n\nskipstart::Int\n \u2013 Specify the number of initial rows to skip. Defaults to \n0\n.\n\n\nskiprows::Vector{Int}\n \u2013 Specify the indices of lines in the input to ignore. Defaults to \n[]\n.\n\n\nskipblanks::Bool\n \u2013 Skip any blank lines in input. Defaults to \ntrue\n.\n\n\nencoding::Symbol\n \u2013 Specify the file's encoding as either \n:utf8\n or \n:latin1\n. Defaults to \n:utf8\n.\n\n\nnormalizenames::Bool\n \u2013 Ensure that column names are valid Julia identifiers. For instance this renames a column named \n\"a b\"\n to \n\"a_b\"\n which can then be accessed with \n:a_b\n instead of \nsymbol(\"a b\")\n. Defaults to \ntrue\n.\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nreadtable\n(\ndata.csv\n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.tsv\n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.wsv\n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.txt\n,\n \nseparator\n \n=\n \n    \n)\n\n\ndf\n \n=\n \nreadtable\n(\ndata.txt\n,\n \nheader\n \n=\n \nfalse\n)\n\n\n\n\n\n\nreadtable\n requires that you specify the path of the file that you would like to read as a \nString\n. To read data from a non-file source, you may also supply an \nIO\n object. It supports many additional keyword arguments: these are documented in the section on advanced I/O operations.\n\n\n\n\nExporting data to a tabular data file\n\n\nTo write data to a CSV file, use the \nwritetable\n function:\n\n\n#\nDataFrames.writetable\n \n \nFunction\n.\n\n\n\n\nWrite data to a tabular-file format (CSV, TSV, ...)\n\n\nwritetable\n(\nfilename\n::\nAbstractString\n,\n\n           \ndf\n::\nAbstractDataFrame\n;\n\n           \nheader\n::\nBool\n \n=\n \ntrue\n,\n\n           \nseparator\n::\nChar\n \n=\n \ngetseparator\n(\nfilename\n),\n\n           \nquotemark\n::\nChar\n \n=\n \n,\n\n           \nnastring\n::\nAbstractString\n \n=\n \nNA\n,\n\n           \nappend\n::\nBool\n \n=\n \nfalse\n)\n\n\n\n\n\n\nArguments\n\n\n\n\nfilename\n : the filename to be created\n\n\ndf\n : the AbstractDataFrame to be written\n\n\n\n\nKeyword Arguments\n\n\n\n\nseparator::Char\n \u2013 The separator character that you would like to use. Defaults to the output of \ngetseparator(filename)\n, which uses commas for files that end in \n.csv\n, tabs for files that end in \n.tsv\n and a single space for files that end in \n.wsv\n.\n\n\nquotemark::Char\n \u2013 The character used to delimit string fields. Defaults to \n'\"'\n.\n\n\nheader::Bool\n \u2013 Should the file contain a header that specifies the column names from \ndf\n. Defaults to \ntrue\n.\n\n\nnastring::AbstractString\n \u2013 What to write in place of missing data. Defaults to \n\"NA\"\n.\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n10\n)\n\n\nwritetable\n(\noutput.csv\n,\n \ndf\n)\n\n\nwritetable\n(\noutput.dat\n,\n \ndf\n,\n \nseparator\n \n=\n \n,\n,\n \nheader\n \n=\n \nfalse\n)\n\n\nwritetable\n(\noutput.dat\n,\n \ndf\n,\n \nquotemark\n \n=\n \n,\n \nseparator\n \n=\n \n,\n)\n\n\nwritetable\n(\noutput.dat\n,\n \ndf\n,\n \nheader\n \n=\n \nfalse\n)\n\n\n\n\n\n\n\n\nSupplying \nDataFrame\ns inline with non-standard string literals\n\n\nYou can also provide CSV-like tabular data in a non-standard string literal to construct a new \nDataFrame\n, as in the following:\n\n\ndf\n \n=\n \ncsv\n\n\n    name,  age, squidPerWeek\n\n\n    Alice,  36,         3.14\n\n\n    Bob,    24,         0\n\n\n    Carol,  58,         2.71\n\n\n    Eve,    49,         7.77\n\n\n    \n\n\n\n\n\n\nThe \ncsv\n string literal prefix indicates that the data are supplied in standard comma-separated value format. Common alternative formats are also available as string literals. For semicolon-separated values, with comma as a decimal, use \ncsv2\n:\n\n\ndf\n \n=\n \ncsv2\n\n\n    name;  age; squidPerWeek\n\n\n    Alice;  36;         3,14\n\n\n    Bob;    24;         0\n\n\n    Carol;  58;         2,71\n\n\n    Eve;    49;         7,77\n\n\n    \n\n\n\n\n\n\nFor whitespace-separated values, use \nwsv\n:\n\n\ndf\n \n=\n \nwsv\n\n\n    name  age squidPerWeek\n\n\n    Alice  36         3.14\n\n\n    Bob    24         0\n\n\n    Carol  58         2.71\n\n\n    Eve    49         7.77\n\n\n    \n\n\n\n\n\n\nAnd for tab-separated values, use \ntsv\n:\n\n\ndf\n \n=\n \ntsv\n\n\n    name    age squidPerWeek\n\n\n    Alice   36  3.14\n\n\n    Bob 24  0\n\n\n    Carol   58  2.71\n\n\n    Eve 49  7.77", 
            "title": "IO"
        }, 
        {
            "location": "/man/io/#importing-and-exporting-io", 
            "text": "", 
            "title": "Importing and Exporting (I/O)"
        }, 
        {
            "location": "/man/io/#importing-data-from-tabular-data-files", 
            "text": "To read data from a CSV-like file, use the  readtable  function:  # DataFrames.readtable     Function .   Read data from a tabular-file format (CSV, TSV, ...)  readtable ( filename ; \n           header :: Bool   =   true , \n           separator :: Char   =   getseparator ( pathname ), \n           quotemark :: Vector { Char }   =   [ ], \n           decimal :: Char   =   . , \n           nastrings :: Vector   =   ASCIIString [ ,   NA ], \n           truestrings :: Vector   =   ASCIIString [ T ,   t ,   TRUE ,   true ], \n           falsestrings :: Vector   =   ASCIIString [ F ,   f ,   FALSE ,   false ], \n           makefactors :: Bool   =   false , \n           nrows :: Integer   =   - 1 , \n           names :: Vector   =   Symbol [], \n           eltypes :: Vector { DataType }   =   DataType [], \n           allowcomments :: Bool   =   false , \n           commentmark :: Char   =   # , \n           ignorepadding :: Bool   =   true , \n           skipstart :: Integer   =   0 , \n           skiprows :: AbstractVector { Int }   =   Int [], \n           skipblanks :: Bool   =   true , \n           encoding :: Symbol   =   : utf8 , \n           allowescapes :: Bool   =   false , \n           normalizenames :: Bool   =   true )", 
            "title": "Importing data from tabular data files"
        }, 
        {
            "location": "/man/io/#arguments", 
            "text": "filename  : the filename to be read", 
            "title": "Arguments"
        }, 
        {
            "location": "/man/io/#keyword-arguments", 
            "text": "header::Bool  \u2013 Use the information from the file's header line to determine column names. Defaults to  true .  separator::Char  \u2013 Assume that fields are split by the  separator  character. If not specified, it will be guessed from the filename:  .csv  defaults to  ',' ,  .tsv  defaults to  '    ' ,  .wsv  defaults to  ' ' .  quotemark::Vector{Char}  \u2013 Assume that fields contained inside of two  quotemark  characters are quoted, which disables processing of separators and linebreaks. Set to  Char[]  to disable this feature and slightly improve performance. Defaults to  ['\"'] .  decimal::Char  \u2013 Assume that the decimal place in numbers is written using the  decimal  character. Defaults to  '.' .  nastrings::Vector{ASCIIString}  \u2013 Translate any of the strings into this vector into an  NA . Defaults to  [\"\", \"NA\"] .  truestrings::Vector{ASCIIString}  \u2013 Translate any of the strings into this vector into a Boolean  true . Defaults to  [\"T\", \"t\", \"TRUE\", \"true\"] .  falsestrings::Vector{ASCIIString}  \u2013 Translate any of the strings into this vector into a Boolean  false . Defaults to  [\"F\", \"f\", \"FALSE\", \"false\"] .  makefactors::Bool  \u2013 Convert string columns into  PooledDataVector 's for use as factors. Defaults to  false .  nrows::Int  \u2013 Read only  nrows  from the file. Defaults to  -1 , which indicates that the entire file should be read.  names::Vector{Symbol}  \u2013 Use the values in this array as the names for all columns instead of or in lieu of the names in the file's header. Defaults to  [] , which indicates that the header should be used if present or that numeric names should be invented if there is no header.  eltypes::Vector{DataType}  \u2013 Specify the types of all columns. Defaults to  [] .  allowcomments::Bool  \u2013 Ignore all text inside comments. Defaults to  false .  commentmark::Char  \u2013 Specify the character that starts comments. Defaults to  '#' .  ignorepadding::Bool  \u2013 Ignore all whitespace on left and right sides of a field. Defaults to  true .  skipstart::Int  \u2013 Specify the number of initial rows to skip. Defaults to  0 .  skiprows::Vector{Int}  \u2013 Specify the indices of lines in the input to ignore. Defaults to  [] .  skipblanks::Bool  \u2013 Skip any blank lines in input. Defaults to  true .  encoding::Symbol  \u2013 Specify the file's encoding as either  :utf8  or  :latin1 . Defaults to  :utf8 .  normalizenames::Bool  \u2013 Ensure that column names are valid Julia identifiers. For instance this renames a column named  \"a b\"  to  \"a_b\"  which can then be accessed with  :a_b  instead of  symbol(\"a b\") . Defaults to  true .", 
            "title": "Keyword Arguments"
        }, 
        {
            "location": "/man/io/#result", 
            "text": "::DataFrame", 
            "title": "Result"
        }, 
        {
            "location": "/man/io/#examples", 
            "text": "df   =   readtable ( data.csv )  df   =   readtable ( data.tsv )  df   =   readtable ( data.wsv )  df   =   readtable ( data.txt ,   separator   =        )  df   =   readtable ( data.txt ,   header   =   false )   readtable  requires that you specify the path of the file that you would like to read as a  String . To read data from a non-file source, you may also supply an  IO  object. It supports many additional keyword arguments: these are documented in the section on advanced I/O operations.", 
            "title": "Examples"
        }, 
        {
            "location": "/man/io/#exporting-data-to-a-tabular-data-file", 
            "text": "To write data to a CSV file, use the  writetable  function:  # DataFrames.writetable     Function .   Write data to a tabular-file format (CSV, TSV, ...)  writetable ( filename :: AbstractString , \n            df :: AbstractDataFrame ; \n            header :: Bool   =   true , \n            separator :: Char   =   getseparator ( filename ), \n            quotemark :: Char   =   , \n            nastring :: AbstractString   =   NA , \n            append :: Bool   =   false )", 
            "title": "Exporting data to a tabular data file"
        }, 
        {
            "location": "/man/io/#arguments_1", 
            "text": "filename  : the filename to be created  df  : the AbstractDataFrame to be written", 
            "title": "Arguments"
        }, 
        {
            "location": "/man/io/#keyword-arguments_1", 
            "text": "separator::Char  \u2013 The separator character that you would like to use. Defaults to the output of  getseparator(filename) , which uses commas for files that end in  .csv , tabs for files that end in  .tsv  and a single space for files that end in  .wsv .  quotemark::Char  \u2013 The character used to delimit string fields. Defaults to  '\"' .  header::Bool  \u2013 Should the file contain a header that specifies the column names from  df . Defaults to  true .  nastring::AbstractString  \u2013 What to write in place of missing data. Defaults to  \"NA\" .", 
            "title": "Keyword Arguments"
        }, 
        {
            "location": "/man/io/#result_1", 
            "text": "::DataFrame", 
            "title": "Result"
        }, 
        {
            "location": "/man/io/#examples_1", 
            "text": "df   =   DataFrame ( A   =   1 : 10 )  writetable ( output.csv ,   df )  writetable ( output.dat ,   df ,   separator   =   , ,   header   =   false )  writetable ( output.dat ,   df ,   quotemark   =   ,   separator   =   , )  writetable ( output.dat ,   df ,   header   =   false )", 
            "title": "Examples"
        }, 
        {
            "location": "/man/io/#supplying-dataframes-inline-with-non-standard-string-literals", 
            "text": "You can also provide CSV-like tabular data in a non-standard string literal to construct a new  DataFrame , as in the following:  df   =   csv      name,  age, squidPerWeek      Alice,  36,         3.14      Bob,    24,         0      Carol,  58,         2.71      Eve,    49,         7.77         The  csv  string literal prefix indicates that the data are supplied in standard comma-separated value format. Common alternative formats are also available as string literals. For semicolon-separated values, with comma as a decimal, use  csv2 :  df   =   csv2      name;  age; squidPerWeek      Alice;  36;         3,14      Bob;    24;         0      Carol;  58;         2,71      Eve;    49;         7,77         For whitespace-separated values, use  wsv :  df   =   wsv      name  age squidPerWeek      Alice  36         3.14      Bob    24         0      Carol  58         2.71      Eve    49         7.77         And for tab-separated values, use  tsv :  df   =   tsv      name    age squidPerWeek      Alice   36  3.14      Bob 24  0      Carol   58  2.71      Eve 49  7.77", 
            "title": "Supplying DataFrames inline with non-standard string literals"
        }, 
        {
            "location": "/man/joins/", 
            "text": "Database-Style Joins\n\n\nWe often need to combine two or more data sets together to provide a complete picture of the topic we are studying. For example, suppose that we have the following two data sets:\n\n\nnames\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n],\n \nName\n \n=\n \n[\nJohn Doe\n,\n \nJane Doe\n])\n\n\njobs\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n],\n \nJob\n \n=\n \n[\nLawyer\n,\n \nDoctor\n])\n\n\n\n\n\n\nWe might want to work with a larger data set that contains both the names and jobs for each ID. We can do this using the \njoin\n function:\n\n\nfull\n \n=\n \njoin\n(\nnames\n,\n \njobs\n,\n \non\n \n=\n \n:\nID\n)\n\n\n\n\n\n\nOutput:\n\n\n\n\n\n\n\n\nRow\n\n\nID\n\n\nName\n\n\nJob\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n\"John Doe\"\n\n\n\"Lawyer\"\n\n\n\n\n\n\n2\n\n\n1\n\n\n\"Jane Doe\"\n\n\n\"Doctor\"\n\n\n\n\n\n\n\n\nIn relational database theory, this operation is generally referred to as a join. The columns used to determine which rows should be combined during a join are called keys.\n\n\nThere are seven kinds of joins supported by the DataFrames package:\n\n\n\n\nInner: The output contains rows for values of the key that exist in both the first (left) and second (right) arguments to \njoin\n.\n\n\nLeft: The output contains rows for values of the key that exist in the first (left) argument to \njoin\n, whether or not that value exists in the second (right) argument.\n\n\nRight: The output contains rows for values of the key that exist in the second (right) argument to \njoin\n, whether or not that value exists in the first (left) argument.\n\n\nOuter: The output contains rows for values of the key that exist in the first (left) or second (right) argument to \njoin\n.\n\n\nSemi: Like an inner join, but output is restricted to columns from the first (left) argument to \njoin\n.\n\n\nAnti: The output contains rows for values of the key that exist in the first (left) but not the second (right) argument to \njoin\n. As with semi joins, output is restricted to columns from the first (left) argument.\n\n\nCross: The output is the cartesian product of rows from the first (left) and second (right) arguments to \njoin\n.\n\n\n\n\nYou can control the kind of join that \njoin\n performs using the \nkind\n keyword argument:\n\n\na\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n],\n \nName\n \n=\n \n[\nA\n,\n \nB\n])\n\n\nb\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n3\n],\n \nJob\n \n=\n \n[\nDoctor\n,\n \nLawyer\n])\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\ninner\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nleft\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nright\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nouter\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nsemi\n)\n\n\njoin\n(\na\n,\n \nb\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nanti\n)\n\n\n\n\n\n\nCross joins are the only kind of join that does not use a key:\n\n\njoin\n(\na\n,\n \nb\n,\n \nkind\n \n=\n \n:\ncross\n)", 
            "title": "Joins"
        }, 
        {
            "location": "/man/joins/#database-style-joins", 
            "text": "We often need to combine two or more data sets together to provide a complete picture of the topic we are studying. For example, suppose that we have the following two data sets:  names   =   DataFrame ( ID   =   [ 1 ,   2 ],   Name   =   [ John Doe ,   Jane Doe ])  jobs   =   DataFrame ( ID   =   [ 1 ,   2 ],   Job   =   [ Lawyer ,   Doctor ])   We might want to work with a larger data set that contains both the names and jobs for each ID. We can do this using the  join  function:  full   =   join ( names ,   jobs ,   on   =   : ID )   Output:     Row  ID  Name  Job      1  1  \"John Doe\"  \"Lawyer\"    2  1  \"Jane Doe\"  \"Doctor\"     In relational database theory, this operation is generally referred to as a join. The columns used to determine which rows should be combined during a join are called keys.  There are seven kinds of joins supported by the DataFrames package:   Inner: The output contains rows for values of the key that exist in both the first (left) and second (right) arguments to  join .  Left: The output contains rows for values of the key that exist in the first (left) argument to  join , whether or not that value exists in the second (right) argument.  Right: The output contains rows for values of the key that exist in the second (right) argument to  join , whether or not that value exists in the first (left) argument.  Outer: The output contains rows for values of the key that exist in the first (left) or second (right) argument to  join .  Semi: Like an inner join, but output is restricted to columns from the first (left) argument to  join .  Anti: The output contains rows for values of the key that exist in the first (left) but not the second (right) argument to  join . As with semi joins, output is restricted to columns from the first (left) argument.  Cross: The output is the cartesian product of rows from the first (left) and second (right) arguments to  join .   You can control the kind of join that  join  performs using the  kind  keyword argument:  a   =   DataFrame ( ID   =   [ 1 ,   2 ],   Name   =   [ A ,   B ])  b   =   DataFrame ( ID   =   [ 1 ,   3 ],   Job   =   [ Doctor ,   Lawyer ])  join ( a ,   b ,   on   =   : ID ,   kind   =   : inner )  join ( a ,   b ,   on   =   : ID ,   kind   =   : left )  join ( a ,   b ,   on   =   : ID ,   kind   =   : right )  join ( a ,   b ,   on   =   : ID ,   kind   =   : outer )  join ( a ,   b ,   on   =   : ID ,   kind   =   : semi )  join ( a ,   b ,   on   =   : ID ,   kind   =   : anti )   Cross joins are the only kind of join that does not use a key:  join ( a ,   b ,   kind   =   : cross )", 
            "title": "Database-Style Joins"
        }, 
        {
            "location": "/man/split_apply_combine/", 
            "text": "The Split-Apply-Combine Strategy\n\n\nMany data analysis tasks involve splitting a data set into groups, applying some functions to each of the groups and then combining the results. A standardized framework for handling this sort of computation is described in the paper, The Split-Apply-Combine Strategy for Data Analysis \\\nhttp://www.jstatsoft.org/v40/i01\n>, written by Hadley Wickham.\n\n\nThe DataFrames package supports the Split-Apply-Combine strategy through the \nby\n function, which takes in three arguments: (1) a DataFrame, (2) a column to split the DataFrame on, and (3) a function or expression to apply to each subset of the DataFrame.\n\n\nWe show several examples of the \nby\n function applied to the \niris\n dataset below:\n\n\nusing\n \nDataFrames\n,\n \nRDatasets\n\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\n\nby\n(\niris\n,\n \n:\nSpecies\n,\n \nsize\n)\n\n\nby\n(\niris\n,\n \n:\nSpecies\n,\n \ndf\n \n-\n \nmean\n(\ndf\n[:\nPetalLength\n]))\n\n\nby\n(\niris\n,\n \n:\nSpecies\n,\n \ndf\n \n-\n \nDataFrame\n(\nN\n \n=\n \nsize\n(\ndf\n,\n \n1\n)))\n\n\n\n\n\n\nThe \nby\n function also support the \ndo\n block form:\n\n\nby\n(\niris\n,\n \n:\nSpecies\n)\n \ndo\n \ndf\n\n   \nDataFrame\n(\nm\n \n=\n \nmean\n(\ndf\n[:\nPetalLength\n]),\n \ns\u00b2\n \n=\n \nvar\n(\ndf\n[:\nPetalLength\n]))\n\n\nend\n\n\n\n\n\n\nA second approach to the Split-Apply-Combine strategy is implemented in the \naggregate\n function, which also takes three arguments: (1) a DataFrame, (2) a column (or columns) to split the DataFrame on, and a (3) function (or several functions) that are used to compute a summary of each subset of the DataFrame. Each function is applied to each column, that was not used to split the DataFrame, creating new columns of the form \n$name_$function\n e.g. \nSepalLength_mean\n. Anonymous functions and expressions that do not have a name will be called \n\u03bb1\n.\n\n\nWe show several examples of the \naggregate\n function applied to the \niris\n dataset below:\n\n\naggregate\n(\niris\n,\n \n:\nSpecies\n,\n \nsum\n)\n\n\naggregate\n(\niris\n,\n \n:\nSpecies\n,\n \n[\nsum\n,\n \nmean\n])\n\n\n\n\n\n\nIf you only want to split the data set into subsets, use the \ngroupby\n function:\n\n\nfor\n \nsubdf\n \nin\n \ngroupby\n(\niris\n,\n \n:\nSpecies\n)\n\n    \nprintln\n(\nsize\n(\nsubdf\n,\n \n1\n))\n\n\nend", 
            "title": "Split-apply-combine"
        }, 
        {
            "location": "/man/split_apply_combine/#the-split-apply-combine-strategy", 
            "text": "Many data analysis tasks involve splitting a data set into groups, applying some functions to each of the groups and then combining the results. A standardized framework for handling this sort of computation is described in the paper, The Split-Apply-Combine Strategy for Data Analysis \\ http://www.jstatsoft.org/v40/i01 >, written by Hadley Wickham.  The DataFrames package supports the Split-Apply-Combine strategy through the  by  function, which takes in three arguments: (1) a DataFrame, (2) a column to split the DataFrame on, and (3) a function or expression to apply to each subset of the DataFrame.  We show several examples of the  by  function applied to the  iris  dataset below:  using   DataFrames ,   RDatasets  iris   =   dataset ( datasets ,   iris )  by ( iris ,   : Species ,   size )  by ( iris ,   : Species ,   df   -   mean ( df [: PetalLength ]))  by ( iris ,   : Species ,   df   -   DataFrame ( N   =   size ( df ,   1 )))   The  by  function also support the  do  block form:  by ( iris ,   : Species )   do   df \n    DataFrame ( m   =   mean ( df [: PetalLength ]),   s\u00b2   =   var ( df [: PetalLength ]))  end   A second approach to the Split-Apply-Combine strategy is implemented in the  aggregate  function, which also takes three arguments: (1) a DataFrame, (2) a column (or columns) to split the DataFrame on, and a (3) function (or several functions) that are used to compute a summary of each subset of the DataFrame. Each function is applied to each column, that was not used to split the DataFrame, creating new columns of the form  $name_$function  e.g.  SepalLength_mean . Anonymous functions and expressions that do not have a name will be called  \u03bb1 .  We show several examples of the  aggregate  function applied to the  iris  dataset below:  aggregate ( iris ,   : Species ,   sum )  aggregate ( iris ,   : Species ,   [ sum ,   mean ])   If you only want to split the data set into subsets, use the  groupby  function:  for   subdf   in   groupby ( iris ,   : Species ) \n     println ( size ( subdf ,   1 ))  end", 
            "title": "The Split-Apply-Combine Strategy"
        }, 
        {
            "location": "/man/reshaping_and_pivoting/", 
            "text": "Reshaping and Pivoting Data\n\n\nReshape data from wide to long format using the \nstack\n function:\n\n\nusing\n \nDataFrames\n,\n \nRDatasets\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\niris\n[:\nid\n]\n \n=\n \n1\n:\nsize\n(\niris\n,\n \n1\n)\n  \n# this makes it easier to unstack\n\n\nd\n \n=\n \nstack\n(\niris\n,\n \n[\n1\n:\n4\n])\n\n\n\n\n\n\nThe second optional argument to \nstack\n indicates the columns to be stacked. These are normally referred to as the measured variables. Column names can also be given:\n\n\nd\n \n=\n \nstack\n(\niris\n,\n \n[:\nSepalLength\n,\n \n:\nSepalWidth\n,\n \n:\nPetalLength\n,\n \n:\nPetalWidth\n])\n\n\n\n\n\n\nNote that all columns can be of different types. Type promotion follows the rules of \nvcat\n.\n\n\nThe stacked DataFrame that results includes all of the columns not specified to be stacked. These are repeated for each stacked column. These are normally refered to as identifier (id) columns. In addition to the id columns, two additional columns labeled \n:variable\n and \n:values\n contain the column identifier and the stacked columns.\n\n\nA third optional argument to \nstack\n represents the id columns that are repeated. This makes it easier to specify which variables you want included in the long format:\n\n\nd\n \n=\n \nstack\n(\niris\n,\n \n[:\nSepalLength\n,\n \n:\nSepalWidth\n],\n \n:\nSpecies\n)\n\n\n\n\n\n\nmelt\n is an alternative function to reshape from wide to long format. It is based on \nstack\n, but it prefers specification of the id columns as:\n\n\nd\n \n=\n \nmelt\n(\niris\n,\n \n:\nSpecies\n)\n\n\n\n\n\n\nAll other columns are assumed to be measured variables (they are stacked).\n\n\nYou can also stack an entire DataFrame. The default stacks all floating-point columns:\n\n\nd\n \n=\n \nstack\n(\niris\n)\n\n\n\n\n\n\nunstack\n converts from a long format to a wide format. The default is requires specifying which columns are an id variable, column variable names, and column values:\n\n\nlongdf\n \n=\n \nmelt\n(\niris\n,\n \n[:\nSpecies\n,\n \n:\nid\n])\n\n\nwidedf\n \n=\n \nunstack\n(\nlongdf\n,\n \n:\nid\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\n\n\n\n\nIf the remaining columns are unique, you can skip the id variable and use:\n\n\nwidedf\n \n=\n \nunstack\n(\nlongdf\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\n\n\n\n\nstackdf\n and \nmeltdf\n are two additional functions that work like \nstack\n and \nmelt\n, but they provide a view into the original wide DataFrame. Here is an example:\n\n\nd\n \n=\n \nstackdf\n(\niris\n)\n\n\n\n\n\n\nThis saves memory. To create the view, several AbstractVectors are defined:\n\n\n:variable\n column \u2013 \nEachRepeatedVector\n   This repeats the variables N times where N is the number of rows of the original AbstractDataFrame.\n\n\n:value\n column \u2013 \nStackedVector\n   This is provides a view of the original columns stacked together.\n\n\nId columns \u2013 \nRepeatedVector\n   This repeats the original columns N times where N is the number of columns stacked.\n\n\nFor more details on the storage representation, see:\n\n\ndump\n(\nstackdf\n(\niris\n))\n\n\n\n\n\n\nNone of these reshaping functions perform any aggregation. To do aggregation, use the split-apply-combine functions in combination with reshaping. Here is an example:\n\n\nd\n \n=\n \nstack\n(\niris\n)\n\n\nx\n \n=\n \nby\n(\nd\n,\n \n[:\nvariable\n,\n \n:\nSpecies\n],\n \ndf\n \n-\n \nDataFrame\n(\nvsum\n \n=\n \nmean\n(\ndf\n[:\nvalue\n])))\n\n\nunstack\n(\nx\n,\n \n:\nSpecies\n,\n \n:\nvsum\n)", 
            "title": "Reshaping"
        }, 
        {
            "location": "/man/reshaping_and_pivoting/#reshaping-and-pivoting-data", 
            "text": "Reshape data from wide to long format using the  stack  function:  using   DataFrames ,   RDatasets  iris   =   dataset ( datasets ,   iris )  iris [: id ]   =   1 : size ( iris ,   1 )    # this makes it easier to unstack  d   =   stack ( iris ,   [ 1 : 4 ])   The second optional argument to  stack  indicates the columns to be stacked. These are normally referred to as the measured variables. Column names can also be given:  d   =   stack ( iris ,   [: SepalLength ,   : SepalWidth ,   : PetalLength ,   : PetalWidth ])   Note that all columns can be of different types. Type promotion follows the rules of  vcat .  The stacked DataFrame that results includes all of the columns not specified to be stacked. These are repeated for each stacked column. These are normally refered to as identifier (id) columns. In addition to the id columns, two additional columns labeled  :variable  and  :values  contain the column identifier and the stacked columns.  A third optional argument to  stack  represents the id columns that are repeated. This makes it easier to specify which variables you want included in the long format:  d   =   stack ( iris ,   [: SepalLength ,   : SepalWidth ],   : Species )   melt  is an alternative function to reshape from wide to long format. It is based on  stack , but it prefers specification of the id columns as:  d   =   melt ( iris ,   : Species )   All other columns are assumed to be measured variables (they are stacked).  You can also stack an entire DataFrame. The default stacks all floating-point columns:  d   =   stack ( iris )   unstack  converts from a long format to a wide format. The default is requires specifying which columns are an id variable, column variable names, and column values:  longdf   =   melt ( iris ,   [: Species ,   : id ])  widedf   =   unstack ( longdf ,   : id ,   : variable ,   : value )   If the remaining columns are unique, you can skip the id variable and use:  widedf   =   unstack ( longdf ,   : variable ,   : value )   stackdf  and  meltdf  are two additional functions that work like  stack  and  melt , but they provide a view into the original wide DataFrame. Here is an example:  d   =   stackdf ( iris )   This saves memory. To create the view, several AbstractVectors are defined:  :variable  column \u2013  EachRepeatedVector    This repeats the variables N times where N is the number of rows of the original AbstractDataFrame.  :value  column \u2013  StackedVector    This is provides a view of the original columns stacked together.  Id columns \u2013  RepeatedVector    This repeats the original columns N times where N is the number of columns stacked.  For more details on the storage representation, see:  dump ( stackdf ( iris ))   None of these reshaping functions perform any aggregation. To do aggregation, use the split-apply-combine functions in combination with reshaping. Here is an example:  d   =   stack ( iris )  x   =   by ( d ,   [: variable ,   : Species ],   df   -   DataFrame ( vsum   =   mean ( df [: value ])))  unstack ( x ,   : Species ,   : vsum )", 
            "title": "Reshaping and Pivoting Data"
        }, 
        {
            "location": "/man/sorting/", 
            "text": "Sorting\n\n\nSorting is a fundamental component of data analysis. Basic sorting is trivial: just calling \nsort!\n will sort all columns, in place:\n\n\nusing\n \nDataFrames\n,\n \nRDatasets\n\n\n\niris\n \n=\n \ndataset\n(\ndatasets\n,\n \niris\n)\n\n\nsort!\n(\niris\n)\n\n\n\n\n\n\nIn Sorting DataFrames, you may want to sort different columns with different options. Here are some examples showing most of the possible options:\n\n\nsort!\n(\niris\n,\n \nrev\n \n=\n \ntrue\n)\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n[:\nSepalWidth\n,\n \n:\nSepalLength\n])\n\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n[\norder\n(:\nSpecies\n,\n \nby\n \n=\n \nuppercase\n),\n\n                    \norder\n(:\nSepalLength\n,\n \nrev\n \n=\n \ntrue\n)])\n\n\n\n\n\n\nKeywords used above include \ncols\n (to specify columns), \nrev\n (to sort a column or the whole DataFrame in reverse), and \nby\n (to apply a function to a column/DataFrame). Each keyword can either be a single value, or can be a tuple or array, with values corresponding to individual columns.\n\n\nAs an alternative to using array or tuple values, \norder\n to specify an ordering for a particular column within a set of columns\n\n\nThe following two examples show two ways to sort the \niris\n dataset with the same result: \nSpecies\n will be ordered in reverse lexicographic order, and within species, rows will be sorted by increasing sepal length and width:\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n(:\nSpecies\n,\n \n:\nSepalLength\n,\n \n:\nSepalWidth\n),\n\n      \nrev\n \n=\n \n(\ntrue\n,\n \nfalse\n,\n \nfalse\n))\n\n\n\nsort!\n(\niris\n,\n \ncols\n \n=\n \n(\norder\n(:\nSpecies\n,\n \nrev\n \n=\n \ntrue\n),\n \n:\nSepalLength\n,\n \n:\nSepalWidth\n))", 
            "title": "Sorting"
        }, 
        {
            "location": "/man/sorting/#sorting", 
            "text": "Sorting is a fundamental component of data analysis. Basic sorting is trivial: just calling  sort!  will sort all columns, in place:  using   DataFrames ,   RDatasets  iris   =   dataset ( datasets ,   iris )  sort! ( iris )   In Sorting DataFrames, you may want to sort different columns with different options. Here are some examples showing most of the possible options:  sort! ( iris ,   rev   =   true )  sort! ( iris ,   cols   =   [: SepalWidth ,   : SepalLength ])  sort! ( iris ,   cols   =   [ order (: Species ,   by   =   uppercase ), \n                     order (: SepalLength ,   rev   =   true )])   Keywords used above include  cols  (to specify columns),  rev  (to sort a column or the whole DataFrame in reverse), and  by  (to apply a function to a column/DataFrame). Each keyword can either be a single value, or can be a tuple or array, with values corresponding to individual columns.  As an alternative to using array or tuple values,  order  to specify an ordering for a particular column within a set of columns  The following two examples show two ways to sort the  iris  dataset with the same result:  Species  will be ordered in reverse lexicographic order, and within species, rows will be sorted by increasing sepal length and width:  sort! ( iris ,   cols   =   (: Species ,   : SepalLength ,   : SepalWidth ), \n       rev   =   ( true ,   false ,   false ))  sort! ( iris ,   cols   =   ( order (: Species ,   rev   =   true ),   : SepalLength ,   : SepalWidth ))", 
            "title": "Sorting"
        }, 
        {
            "location": "/man/formulas/", 
            "text": "The Formula, ModelFrame and ModelMatrix Types\n\n\nIn regression analysis, we often want to describe the relationship between a response variable and one or more input variables in terms of main effects and interactions. To facilitate the specification of a regression model in terms of the columns of a \nDataFrame\n, the DataFrames package provides a \nFormula\n type, which is created by the \n~\n binary operator in Julia:\n\n\nfm\n \n=\n \nZ\n \n~\n \nX\n \n+\n \nY\n\n\n\n\n\n\nA \nFormula\n object can be used to transform a \nDataFrame\n into a \nModelFrame\n object:\n\n\ndf\n \n=\n \nDataFrame\n(\nX\n \n=\n \nrandn\n(\n10\n),\n \nY\n \n=\n \nrandn\n(\n10\n),\n \nZ\n \n=\n \nrandn\n(\n10\n))\n\n\nmf\n \n=\n \nModelFrame\n(\nZ\n \n~\n \nX\n \n+\n \nY\n,\n \ndf\n)\n\n\n\n\n\n\nA \nModelFrame\n object is just a simple wrapper around a \nDataFrame\n. For modeling purposes, one generally wants to construct a \nModelMatrix\n, which constructs a \nMatrix{Float64}\n that can be used directly to fit a statistical model:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\nZ\n \n~\n \nX\n \n+\n \nY\n,\n \ndf\n))\n\n\n\n\n\n\nNote that \nmm\n contains an additional column consisting entirely of \n1.0\n values. This is used to fit an intercept term in a regression model.\n\n\nIn addition to specifying main effects, it is possible to specify interactions using the \n operator inside a \nFormula\n:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\nZ\n \n~\n \nX\n \n+\n \nY\n \n+\n \nX\nY\n,\n \ndf\n))\n\n\n\n\n\n\nIf you would like to specify both main effects and an interaction term at once, use the \n*\n operator inside a \nFormula\n:\n\n\nmm\n \n=\n \nModelMatrix\n(\nModelFrame\n(\nZ\n \n~\n \nX\n*\nY\n,\n \ndf\n))\n\n\n\n\n\n\nThe construction of model matrices makes it easy to formulate complex statistical models. These are used to good effect by the \nGLM Package.", 
            "title": "Formulas"
        }, 
        {
            "location": "/man/formulas/#the-formula-modelframe-and-modelmatrix-types", 
            "text": "In regression analysis, we often want to describe the relationship between a response variable and one or more input variables in terms of main effects and interactions. To facilitate the specification of a regression model in terms of the columns of a  DataFrame , the DataFrames package provides a  Formula  type, which is created by the  ~  binary operator in Julia:  fm   =   Z   ~   X   +   Y   A  Formula  object can be used to transform a  DataFrame  into a  ModelFrame  object:  df   =   DataFrame ( X   =   randn ( 10 ),   Y   =   randn ( 10 ),   Z   =   randn ( 10 ))  mf   =   ModelFrame ( Z   ~   X   +   Y ,   df )   A  ModelFrame  object is just a simple wrapper around a  DataFrame . For modeling purposes, one generally wants to construct a  ModelMatrix , which constructs a  Matrix{Float64}  that can be used directly to fit a statistical model:  mm   =   ModelMatrix ( ModelFrame ( Z   ~   X   +   Y ,   df ))   Note that  mm  contains an additional column consisting entirely of  1.0  values. This is used to fit an intercept term in a regression model.  In addition to specifying main effects, it is possible to specify interactions using the   operator inside a  Formula :  mm   =   ModelMatrix ( ModelFrame ( Z   ~   X   +   Y   +   X Y ,   df ))   If you would like to specify both main effects and an interaction term at once, use the  *  operator inside a  Formula :  mm   =   ModelMatrix ( ModelFrame ( Z   ~   X * Y ,   df ))   The construction of model matrices makes it easy to formulate complex statistical models. These are used to good effect by the  GLM Package.", 
            "title": "The Formula, ModelFrame and ModelMatrix Types"
        }, 
        {
            "location": "/man/pooling/", 
            "text": "Pooling Data (Representing Factors)\n\n\nOften, we have to deal with factors that take on a small number of levels:\n\n\ndv\n \n=\n \n@\ndata\n([\nGroup A\n,\n \nGroup A\n,\n \nGroup A\n,\n\n            \nGroup B\n,\n \nGroup B\n,\n \nGroup B\n])\n\n\n\n\n\n\nThe naive encoding used in a \nDataArray\n represents every entry of this vector as a full string. In contrast, we can represent the data more efficiently by replacing the strings with indices into a small pool of levels. This is what the \nPooledDataArray\n does:\n\n\npdv\n \n=\n \n@\npdata\n([\nGroup A\n,\n \nGroup A\n,\n \nGroup A\n,\n\n              \nGroup B\n,\n \nGroup B\n,\n \nGroup B\n])\n\n\n\n\n\n\nIn addition to representing repeated data efficiently, the \nPooledDataArray\n allows us to determine the levels of the factor at any time using the \nlevels\n function:\n\n\nlevels\n(\npdv\n)\n\n\n\n\n\n\nBy default, a \nPooledDataArray\n is able to represent 2\n32\ndifferents levels. You can use less memory by calling the \ncompact\n function:\n\n\npdv\n \n=\n \ncompact\n(\npdv\n)\n\n\n\n\n\n\nOften, you will have factors encoded inside a DataFrame with \nDataArray\n columns instead of \nPooledDataArray\n columns. You can do conversion of a single column using the \npool\n function:\n\n\npdv\n \n=\n \npool\n(\ndv\n)\n\n\n\n\n\n\nOr you can edit the columns of a \nDataFrame\n in-place using the \npool!\n function:\n\n\ndf\n \n=\n \nDataFrame\n(\nA\n \n=\n \n[\n1\n,\n \n1\n,\n \n1\n,\n \n2\n,\n \n2\n,\n \n2\n],\n\n               \nB\n \n=\n \n[\nX\n,\n \nX\n,\n \nX\n,\n \nY\n,\n \nY\n,\n \nY\n])\n\n\npool!\n(\ndf\n,\n \n[:\nA\n,\n \n:\nB\n])\n\n\n\n\n\n\nPooling columns is important for working with the \nGLM package\n When fitting regression models, \nPooledDataArray\n columns in the input are translated into 0/1 indicator columns in the \nModelMatrix\n with one column for each of the levels of the \nPooledDataArray\n. This allows one to analyze categorical data efficiently.", 
            "title": "Pooling"
        }, 
        {
            "location": "/man/pooling/#pooling-data-representing-factors", 
            "text": "Often, we have to deal with factors that take on a small number of levels:  dv   =   @ data ([ Group A ,   Group A ,   Group A , \n             Group B ,   Group B ,   Group B ])   The naive encoding used in a  DataArray  represents every entry of this vector as a full string. In contrast, we can represent the data more efficiently by replacing the strings with indices into a small pool of levels. This is what the  PooledDataArray  does:  pdv   =   @ pdata ([ Group A ,   Group A ,   Group A , \n               Group B ,   Group B ,   Group B ])   In addition to representing repeated data efficiently, the  PooledDataArray  allows us to determine the levels of the factor at any time using the  levels  function:  levels ( pdv )   By default, a  PooledDataArray  is able to represent 2 32 differents levels. You can use less memory by calling the  compact  function:  pdv   =   compact ( pdv )   Often, you will have factors encoded inside a DataFrame with  DataArray  columns instead of  PooledDataArray  columns. You can do conversion of a single column using the  pool  function:  pdv   =   pool ( dv )   Or you can edit the columns of a  DataFrame  in-place using the  pool!  function:  df   =   DataFrame ( A   =   [ 1 ,   1 ,   1 ,   2 ,   2 ,   2 ], \n                B   =   [ X ,   X ,   X ,   Y ,   Y ,   Y ])  pool! ( df ,   [: A ,   : B ])   Pooling columns is important for working with the  GLM package  When fitting regression models,  PooledDataArray  columns in the input are translated into 0/1 indicator columns in the  ModelMatrix  with one column for each of the levels of the  PooledDataArray . This allows one to analyze categorical data efficiently.", 
            "title": "Pooling Data (Representing Factors)"
        }, 
        {
            "location": "/lib/maintypes/", 
            "text": "Main Types\n\n\n\n\nAbstractDataFrame\n\n\nDataFrame\n\n\nSubDataFrame\n\n\n\n\n...\n\n\n#\nDataFrames.AbstractDataFrame\n \n \nType\n.\n\n\n\n\nAn abstract type for which all concrete types expose a database-like interface.\n\n\nCommon methods\n\n\nAn AbstractDataFrame is a two-dimensional table with Symbols for column names. An AbstractDataFrame is also similar to an Associative type in that it allows indexing by a key (the columns).\n\n\nThe following are normally implemented for AbstractDataFrames:\n\n\n\n\ndescribe\n : summarize columns\n\n\ndump\n : show structure\n\n\nhcat\n : horizontal concatenation\n\n\nvcat\n : vertical concatenation\n\n\nnames\n : columns names\n\n\nnames!\n : set columns names\n\n\nrename!\n : rename columns names based on keyword arguments\n\n\neltypes\n : \neltype\n of each column\n\n\nlength\n : number of columns\n\n\nsize\n : (nrows, ncols)\n\n\nhead\n : first \nn\n rows\n\n\ntail\n : last \nn\n rows\n\n\nconvert\n : convert to an array\n\n\nDataArray\n : convert to a DataArray\n\n\ncomplete_cases\n : indexes of complete cases (rows with no NA's)\n\n\ncomplete_cases!\n : remove rows with NA's\n\n\nnonunique\n : indexes of duplicate rows\n\n\nunique!\n : remove duplicate rows\n\n\nsimilar\n : a DataFrame with similar columns as \nd\n\n\n\n\nIndexing\n\n\nTable columns are accessed (\ngetindex\n) by a single index that can be a symbol identifier, an integer, or a vector of each. If a single column is selected, just the column object is returned. If multiple columns are selected, some AbstractDataFrame is returned.\n\n\nd\n[:\ncolA\n]\n\n\nd\n[\n3\n]\n\n\nd\n[[:\ncolA\n,\n \n:\ncolB\n]]\n\n\nd\n[[\n1\n:\n3\n;\n \n5\n]]\n\n\n\n\n\n\nRows and columns can be indexed like a \nMatrix\n with the added feature of indexing columns by name.\n\n\nd\n[\n1\n:\n3\n,\n \n:\ncolA\n]\n\n\nd\n[\n3\n,\n3\n]\n\n\nd\n[\n3\n,:]\n\n\nd\n[\n3\n,[:\ncolA\n,\n \n:\ncolB\n]]\n\n\nd\n[:,\n \n[:\ncolA\n,\n \n:\ncolB\n]]\n\n\nd\n[[\n1\n:\n3\n;\n \n5\n],\n \n:]\n\n\n\n\n\n\nsetindex\n works similarly.\n\n\n#\nDataFrames.DataFrame\n \n \nType\n.\n\n\n\n\nAn AbstractDataFrame that stores a set of named columns\n\n\nThe columns are normally AbstractVectors stored in memory, particularly a Vector, DataVector, or PooledDataVector.\n\n\nConstructors\n\n\nDataFrame\n(\ncolumns\n::\nVector\n{\nAny\n},\n \nnames\n::\nVector\n{\nSymbol\n})\n\n\nDataFrame\n(\nkwargs\n...\n)\n\n\nDataFrame\n()\n \n# an empty DataFrame\n\n\nDataFrame\n(\nt\n::\nType\n,\n \nnrows\n::\nInteger\n,\n \nncols\n::\nInteger\n)\n \n# an empty DataFrame of arbitrary size\n\n\nDataFrame\n(\ncolumn_eltypes\n::\nVector\n,\n \nnames\n::\nVector\n,\n \nnrows\n::\nInteger\n)\n\n\nDataFrame\n(\nds\n::\nVector\n{\nAssociative\n})\n\n\n\n\n\n\nArguments\n\n\n\n\ncolumns\n : a Vector{Any} with each column as contents\n\n\nnames\n : the column names\n\n\nkwargs\n : the key gives the column names, and the value is the   column contents\n\n\nt\n : elemental type of all columns\n\n\nnrows\n, \nncols\n : number of rows and columns\n\n\ncolumn_eltypes\n : elemental type of each column\n\n\nds\n : a vector of Associatives\n\n\n\n\nEach column in \ncolumns\n should be the same length.\n\n\nNotes\n\n\nMost of the default constructors convert columns to \nDataArrays\n.  The base constructor, \nDataFrame(columns::Vector{Any}, names::Vector{Symbol})\n does not convert to \nDataArrays\n.\n\n\nA \nDataFrame\n is a lightweight object. As long as columns are not manipulated, creation of a DataFrame from existing AbstractVectors is inexpensive. For example, indexing on columns is inexpensive, but indexing by rows is expensive because copies are made of each column.\n\n\nBecause column types can vary, a DataFrame is not type stable. For performance-critical code, do not index into a DataFrame inside of loops.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n()\n\n\nv\n \n=\n \n[\nx\n,\ny\n,\nz\n][\nrand\n(\n1\n:\n3\n,\n \n10\n)]\n\n\ndf1\n \n=\n \nDataFrame\n(\nAny\n[[\n1\n:\n10\n],\n \nv\n,\n \nrand\n(\n10\n)],\n \n[:\nA\n,\n \n:\nB\n,\n \n:\nC\n])\n  \n# columns are Arrays\n\n\ndf2\n \n=\n \nDataFrame\n(\nA\n \n=\n \n1\n:\n10\n,\n \nB\n \n=\n \nv\n,\n \nC\n \n=\n \nrand\n(\n10\n))\n           \n# columns are DataArrays\n\n\ndump\n(\ndf1\n)\n\n\ndump\n(\ndf2\n)\n\n\ndescribe\n(\ndf2\n)\n\n\nhead\n(\ndf1\n)\n\n\ndf1\n[:\nA\n]\n \n+\n \ndf2\n[:\nC\n]\n\n\ndf1\n[\n1\n:\n4\n,\n \n1\n:\n2\n]\n\n\ndf1\n[[:\nA\n,:\nC\n]]\n\n\ndf1\n[\n1\n:\n2\n,\n \n[:\nA\n,:\nC\n]]\n\n\ndf1\n[:,\n \n[:\nA\n,:\nC\n]]\n\n\ndf1\n[:,\n \n[\n1\n,\n3\n]]\n\n\ndf1\n[\n1\n:\n4\n,\n \n:]\n\n\ndf1\n[\n1\n:\n4\n,\n \n:\nC\n]\n\n\ndf1\n[\n1\n:\n4\n,\n \n:\nC\n]\n \n=\n \n40.\n \n*\n \ndf1\n[\n1\n:\n4\n,\n \n:\nC\n]\n\n\n[\ndf1\n;\n \ndf2\n]\n  \n# vcat\n\n\n[\ndf1\n  \ndf2\n]\n  \n# hcat\n\n\nsize\n(\ndf1\n)\n\n\n\n\n\n\n#\nDataFrames.SubDataFrame\n \n \nType\n.\n\n\n\n\nA view of row subsets of an AbstractDataFrame\n\n\nA \nSubDataFrame\n is meant to be constructed with \nsub\n.  A SubDataFrame is used frequently in split/apply sorts of operations.\n\n\nsub\n(\nd\n::\nAbstractDataFrame\n,\n \nrows\n)\n\n\n\n\n\n\nArguments\n\n\n\n\nd\n : an AbstractDataFrame\n\n\nrows\n : any indexing type for rows, typically an Int,   AbstractVector{Int}, AbstractVector{Bool}, or a Range\n\n\n\n\nNotes\n\n\nA \nSubDataFrame\n is an AbstractDataFrame, so expect that most DataFrame functions should work. Such methods include \ndescribe\n, \ndump\n, \nnrow\n, \nsize\n, \nby\n, \nstack\n, and \njoin\n. Indexing is just like a DataFrame; copies are returned.\n\n\nTo subset along columns, use standard column indexing as that creates a view to the columns by default. To subset along rows and columns, use column-based indexing with \nsub\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\na\n \n=\n \nrep\n(\n1\n:\n4\n,\n \n2\n),\n \nb\n \n=\n \nrep\n(\n2\n:\n-\n1\n:\n1\n,\n \n4\n),\n \nc\n \n=\n \nrandn\n(\n8\n))\n\n\nsdf1\n \n=\n \nsub\n(\ndf\n,\n \n1\n:\n6\n)\n\n\nsdf2\n \n=\n \nsub\n(\ndf\n,\n \ndf\n[:\na\n]\n \n.\n \n1\n)\n\n\nsdf3\n \n=\n \nsub\n(\ndf\n[[\n1\n,\n3\n]],\n \ndf\n[:\na\n]\n \n.\n \n1\n)\n  \n# row and column subsetting\n\n\nsdf4\n \n=\n \ngroupby\n(\ndf\n,\n \n:\na\n)[\n1\n]\n  \n# indexing a GroupedDataFrame returns a SubDataFrame\n\n\nsdf5\n \n=\n \nsub\n(\nsdf1\n,\n \n1\n:\n3\n)\n\n\nsdf1\n[:,[:\na\n,:\nb\n]]", 
            "title": "Main types"
        }, 
        {
            "location": "/lib/maintypes/#main-types", 
            "text": "AbstractDataFrame  DataFrame  SubDataFrame   ...  # DataFrames.AbstractDataFrame     Type .   An abstract type for which all concrete types expose a database-like interface.  Common methods  An AbstractDataFrame is a two-dimensional table with Symbols for column names. An AbstractDataFrame is also similar to an Associative type in that it allows indexing by a key (the columns).  The following are normally implemented for AbstractDataFrames:   describe  : summarize columns  dump  : show structure  hcat  : horizontal concatenation  vcat  : vertical concatenation  names  : columns names  names!  : set columns names  rename!  : rename columns names based on keyword arguments  eltypes  :  eltype  of each column  length  : number of columns  size  : (nrows, ncols)  head  : first  n  rows  tail  : last  n  rows  convert  : convert to an array  DataArray  : convert to a DataArray  complete_cases  : indexes of complete cases (rows with no NA's)  complete_cases!  : remove rows with NA's  nonunique  : indexes of duplicate rows  unique!  : remove duplicate rows  similar  : a DataFrame with similar columns as  d   Indexing  Table columns are accessed ( getindex ) by a single index that can be a symbol identifier, an integer, or a vector of each. If a single column is selected, just the column object is returned. If multiple columns are selected, some AbstractDataFrame is returned.  d [: colA ]  d [ 3 ]  d [[: colA ,   : colB ]]  d [[ 1 : 3 ;   5 ]]   Rows and columns can be indexed like a  Matrix  with the added feature of indexing columns by name.  d [ 1 : 3 ,   : colA ]  d [ 3 , 3 ]  d [ 3 ,:]  d [ 3 ,[: colA ,   : colB ]]  d [:,   [: colA ,   : colB ]]  d [[ 1 : 3 ;   5 ],   :]   setindex  works similarly.  # DataFrames.DataFrame     Type .   An AbstractDataFrame that stores a set of named columns  The columns are normally AbstractVectors stored in memory, particularly a Vector, DataVector, or PooledDataVector.  Constructors  DataFrame ( columns :: Vector { Any },   names :: Vector { Symbol })  DataFrame ( kwargs ... )  DataFrame ()   # an empty DataFrame  DataFrame ( t :: Type ,   nrows :: Integer ,   ncols :: Integer )   # an empty DataFrame of arbitrary size  DataFrame ( column_eltypes :: Vector ,   names :: Vector ,   nrows :: Integer )  DataFrame ( ds :: Vector { Associative })   Arguments   columns  : a Vector{Any} with each column as contents  names  : the column names  kwargs  : the key gives the column names, and the value is the   column contents  t  : elemental type of all columns  nrows ,  ncols  : number of rows and columns  column_eltypes  : elemental type of each column  ds  : a vector of Associatives   Each column in  columns  should be the same length.  Notes  Most of the default constructors convert columns to  DataArrays .  The base constructor,  DataFrame(columns::Vector{Any}, names::Vector{Symbol})  does not convert to  DataArrays .  A  DataFrame  is a lightweight object. As long as columns are not manipulated, creation of a DataFrame from existing AbstractVectors is inexpensive. For example, indexing on columns is inexpensive, but indexing by rows is expensive because copies are made of each column.  Because column types can vary, a DataFrame is not type stable. For performance-critical code, do not index into a DataFrame inside of loops.  Examples  df   =   DataFrame ()  v   =   [ x , y , z ][ rand ( 1 : 3 ,   10 )]  df1   =   DataFrame ( Any [[ 1 : 10 ],   v ,   rand ( 10 )],   [: A ,   : B ,   : C ])    # columns are Arrays  df2   =   DataFrame ( A   =   1 : 10 ,   B   =   v ,   C   =   rand ( 10 ))             # columns are DataArrays  dump ( df1 )  dump ( df2 )  describe ( df2 )  head ( df1 )  df1 [: A ]   +   df2 [: C ]  df1 [ 1 : 4 ,   1 : 2 ]  df1 [[: A ,: C ]]  df1 [ 1 : 2 ,   [: A ,: C ]]  df1 [:,   [: A ,: C ]]  df1 [:,   [ 1 , 3 ]]  df1 [ 1 : 4 ,   :]  df1 [ 1 : 4 ,   : C ]  df1 [ 1 : 4 ,   : C ]   =   40.   *   df1 [ 1 : 4 ,   : C ]  [ df1 ;   df2 ]    # vcat  [ df1    df2 ]    # hcat  size ( df1 )   # DataFrames.SubDataFrame     Type .   A view of row subsets of an AbstractDataFrame  A  SubDataFrame  is meant to be constructed with  sub .  A SubDataFrame is used frequently in split/apply sorts of operations.  sub ( d :: AbstractDataFrame ,   rows )", 
            "title": "Main Types"
        }, 
        {
            "location": "/lib/maintypes/#arguments", 
            "text": "d  : an AbstractDataFrame  rows  : any indexing type for rows, typically an Int,   AbstractVector{Int}, AbstractVector{Bool}, or a Range", 
            "title": "Arguments"
        }, 
        {
            "location": "/lib/maintypes/#notes", 
            "text": "A  SubDataFrame  is an AbstractDataFrame, so expect that most DataFrame functions should work. Such methods include  describe ,  dump ,  nrow ,  size ,  by ,  stack , and  join . Indexing is just like a DataFrame; copies are returned.  To subset along columns, use standard column indexing as that creates a view to the columns by default. To subset along rows and columns, use column-based indexing with  sub .", 
            "title": "Notes"
        }, 
        {
            "location": "/lib/maintypes/#examples", 
            "text": "df   =   DataFrame ( a   =   rep ( 1 : 4 ,   2 ),   b   =   rep ( 2 : - 1 : 1 ,   4 ),   c   =   randn ( 8 ))  sdf1   =   sub ( df ,   1 : 6 )  sdf2   =   sub ( df ,   df [: a ]   .   1 )  sdf3   =   sub ( df [[ 1 , 3 ]],   df [: a ]   .   1 )    # row and column subsetting  sdf4   =   groupby ( df ,   : a )[ 1 ]    # indexing a GroupedDataFrame returns a SubDataFrame  sdf5   =   sub ( sdf1 ,   1 : 3 )  sdf1 [:,[: a ,: b ]]", 
            "title": "Examples"
        }, 
        {
            "location": "/lib/utilities/", 
            "text": "Utilities\n\n\n\n\ndump\n\n\nunique\n\n\nhead\n\n\ntail\n\n\ncomplete_cases\n\n\ncomplete_cases!\n\n\neltypes\n\n\nnames!\n\n\nnonunique\n\n\nrename\n\n\nrename!\n\n\nunique!\n\n\ndescribe\n\n\n\n\n...\n\n\n#\nDataFrames.eltypes\n \n \nFunction\n.\n\n\n\n\nColumn elemental types\n\n\neltypes\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::Vector{Type}\n : the elemental type of each column\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\neltypes\n(\ndf\n)\n\n\n\n\n\n\n#\nDataArrays.head\n \n \nFunction\n.\n\n\n\n\nShow the first or last part of an AbstractDataFrame\n\n\nhead\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\ntail\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nr\n : the number of rows to show\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the first or last part of \ndf\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nhead\n(\ndf\n)\n\n\ntail\n(\ndf\n)\n\n\n\n\n\n\n#\nDataFrames.complete_cases\n \n \nFunction\n.\n\n\n\n\nIndexes of complete cases (rows without NA's)\n\n\ncomplete_cases\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::Vector{Bool}\n : indexes of complete cases\n\n\n\n\nSee also \ncomplete_cases!\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n[[\n1\n,\n4\n,\n5\n],\n \n:\nx\n]\n \n=\n \nNA\n\n\ndf\n[[\n9\n,\n10\n],\n \n:\ny\n]\n \n=\n \nNA\n\n\ncomplete_cases\n(\ndf\n)\n\n\n\n\n\n\n#\nDataFrames.complete_cases!\n \n \nFunction\n.\n\n\n\n\nDelete rows with NA's.\n\n\ncomplete_cases!\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated version\n\n\n\n\nSee also \ncomplete_cases\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n[[\n1\n,\n4\n,\n5\n],\n \n:\nx\n]\n \n=\n \nNA\n\n\ndf\n[[\n9\n,\n10\n],\n \n:\ny\n]\n \n=\n \nNA\n\n\ncomplete_cases!\n(\ndf\n)\n\n\n\n\n\n\n#\nStatsBase.describe\n \n \nFunction\n.\n\n\n\n\nSummarize the columns of an AbstractDataFrame\n\n\ndescribe\n(\ndf\n::\nAbstractDataFrame\n)\n\n\ndescribe\n(\nio\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nio\n : optional output descriptor\n\n\n\n\nResult\n\n\n\n\nnothing\n\n\n\n\nDetails\n\n\nIf the column's base type derives from Number, compute the minimum, first quantile, median, mean, third quantile, and maximum. NA's are filtered and reported separately.\n\n\nFor boolean columns, report trues, falses, and NAs.\n\n\nFor other types, show column characteristics and number of NAs.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndescribe\n(\ndf\n)\n\n\n\n\n\n\n#\nBase.dump\n \n \nFunction\n.\n\n\n\n\nShow the structure of an AbstractDataFrame, in a tree-like format\n\n\ndump\n(\ndf\n::\nAbstractDataFrame\n,\n \nn\n::\nInt\n \n=\n \n5\n)\n\n\ndump\n(\nio\n::\nIO\n,\n \ndf\n::\nAbstractDataFrame\n,\n \nn\n::\nInt\n \n=\n \n5\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nn\n : the number of levels to show\n\n\nio\n : optional output descriptor\n\n\n\n\nResult\n\n\n\n\nnothing\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nstr\n(\ndf\n)\n\n\n\n\n\n\n#\nDataFrames.names!\n \n \nFunction\n.\n\n\n\n\nSet column names\n\n\nnames!\n(\ndf\n::\nAbstractDataFrame\n,\n \nvals\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nvals\n : column names, normally a Vector{Symbol} the same length as   the number of columns in \ndf\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated result\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nnames!\n(\ndf\n,\n \n[:\na\n,\n \n:\nb\n,\n \n:\nc\n])\n\n\n\n\n\n\n#\nDataFrames.nonunique\n \n \nFunction\n.\n\n\n\n\nIndexes of complete cases (rows without NA's)\n\n\nnonunique\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::Vector{Bool}\n : indicates whether the row is a duplicate of some   prior row\n\n\n\n\nSee also \nunique\n and \nunique!\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n \n=\n \nvcat\n(\ndf\n,\n \ndf\n)\n\n\nnonunique\n(\ndf\n)\n\n\n\n\n\n\n#\nDataFrames.rename\n \n \nFunction\n.\n\n\n\n\nRename columns\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nd\n::\nAssociative\n)\n\n\nrename!\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\nrename\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nd\n : an Associative type that maps the original name to a new name\n\n\nf\n : a function that has the old column name (a symbol) as input   and new column name (a symbol) as output\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated result\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nrename\n(\nx\n \n-\n \nsymbol\n(\nuppercase\n(\nstring\n(\nx\n))),\n \ndf\n)\n\n\nrename\n(\ndf\n,\n \n@\ncompat\n(\nDict\n(:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n)))\n\n\nrename\n(\ndf\n,\n \n:\ny\n,\n \n:\nY\n)\n\n\nrename!\n(\ndf\n,\n \n@\ncompat\n(\nDict\n(:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n)))\n\n\n\n\n\n\n#\nDataFrames.rename!\n \n \nFunction\n.\n\n\n\n\nRename columns\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename!\n(\ndf\n::\nAbstractDataFrame\n,\n \nd\n::\nAssociative\n)\n\n\nrename!\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\nrename\n(\ndf\n::\nAbstractDataFrame\n,\n \nfrom\n::\nSymbol\n,\n \nto\n::\nSymbol\n)\n\n\nrename\n(\nf\n::\nFunction\n,\n \ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nd\n : an Associative type that maps the original name to a new name\n\n\nf\n : a function that has the old column name (a symbol) as input   and new column name (a symbol) as output\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated result\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nrename\n(\nx\n \n-\n \nsymbol\n(\nuppercase\n(\nstring\n(\nx\n))),\n \ndf\n)\n\n\nrename\n(\ndf\n,\n \n@\ncompat\n(\nDict\n(:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n)))\n\n\nrename\n(\ndf\n,\n \n:\ny\n,\n \n:\nY\n)\n\n\nrename!\n(\ndf\n,\n \n@\ncompat\n(\nDict\n(:\ni\n=\n:\nA\n,\n \n:\nx\n=\n:\nX\n)))\n\n\n\n\n\n\n#\nDataArrays.tail\n \n \nFunction\n.\n\n\n\n\nShow the first or last part of an AbstractDataFrame\n\n\nhead\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\ntail\n(\ndf\n::\nAbstractDataFrame\n,\n \nr\n::\nInt\n \n=\n \n6\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\nr\n : the number of rows to show\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the first or last part of \ndf\n\n\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\nhead\n(\ndf\n)\n\n\ntail\n(\ndf\n)\n\n\n\n\n\n\n#\nBase.unique\n \n \nFunction\n.\n\n\n\n\nDelete duplicate rows\n\n\nunique\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nunique!\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated version\n\n\n\n\nSee also \nnonunique\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n \n=\n \nvcat\n(\ndf\n,\n \ndf\n)\n\n\nunique\n(\ndf\n)\n   \n# doesn\nt modify df\n\n\nunique!\n(\ndf\n)\n  \n# modifies df\n\n\n\n\n\n\n#\nDataFrames.unique!\n \n \nFunction\n.\n\n\n\n\nDelete duplicate rows\n\n\nunique\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nunique!\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf\n : the AbstractDataFrame\n\n\n\n\nResult\n\n\n\n\n::AbstractDataFrame\n : the updated version\n\n\n\n\nSee also \nnonunique\n.\n\n\nExamples\n\n\ndf\n \n=\n \nDataFrame\n(\ni\n \n=\n \n1\n:\n10\n,\n \nx\n \n=\n \nrand\n(\n10\n),\n \ny\n \n=\n \nrand\n([\na\n,\n \nb\n,\n \nc\n],\n \n10\n))\n\n\ndf\n \n=\n \nvcat\n(\ndf\n,\n \ndf\n)\n\n\nunique\n(\ndf\n)\n   \n# doesn\nt modify df\n\n\nunique!\n(\ndf\n)\n  \n# modifies df", 
            "title": "Utilities"
        }, 
        {
            "location": "/lib/utilities/#utilities", 
            "text": "dump  unique  head  tail  complete_cases  complete_cases!  eltypes  names!  nonunique  rename  rename!  unique!  describe   ...  # DataFrames.eltypes     Function .   Column elemental types  eltypes ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::Vector{Type}  : the elemental type of each column   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  eltypes ( df )   # DataArrays.head     Function .   Show the first or last part of an AbstractDataFrame  head ( df :: AbstractDataFrame ,   r :: Int   =   6 )  tail ( df :: AbstractDataFrame ,   r :: Int   =   6 )   Arguments   df  : the AbstractDataFrame  r  : the number of rows to show   Result   ::AbstractDataFrame  : the first or last part of  df   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  head ( df )  tail ( df )   # DataFrames.complete_cases     Function .   Indexes of complete cases (rows without NA's)  complete_cases ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::Vector{Bool}  : indexes of complete cases   See also  complete_cases! .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df [[ 1 , 4 , 5 ],   : x ]   =   NA  df [[ 9 , 10 ],   : y ]   =   NA  complete_cases ( df )   # DataFrames.complete_cases!     Function .   Delete rows with NA's.  complete_cases! ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::AbstractDataFrame  : the updated version   See also  complete_cases .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df [[ 1 , 4 , 5 ],   : x ]   =   NA  df [[ 9 , 10 ],   : y ]   =   NA  complete_cases! ( df )   # StatsBase.describe     Function .   Summarize the columns of an AbstractDataFrame  describe ( df :: AbstractDataFrame )  describe ( io ,   df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame  io  : optional output descriptor   Result   nothing   Details  If the column's base type derives from Number, compute the minimum, first quantile, median, mean, third quantile, and maximum. NA's are filtered and reported separately.  For boolean columns, report trues, falses, and NAs.  For other types, show column characteristics and number of NAs.  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  describe ( df )   # Base.dump     Function .   Show the structure of an AbstractDataFrame, in a tree-like format  dump ( df :: AbstractDataFrame ,   n :: Int   =   5 )  dump ( io :: IO ,   df :: AbstractDataFrame ,   n :: Int   =   5 )   Arguments   df  : the AbstractDataFrame  n  : the number of levels to show  io  : optional output descriptor   Result   nothing   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  str ( df )   # DataFrames.names!     Function .   Set column names  names! ( df :: AbstractDataFrame ,   vals )   Arguments   df  : the AbstractDataFrame  vals  : column names, normally a Vector{Symbol} the same length as   the number of columns in  df   Result   ::AbstractDataFrame  : the updated result   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  names! ( df ,   [: a ,   : b ,   : c ])   # DataFrames.nonunique     Function .   Indexes of complete cases (rows without NA's)  nonunique ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::Vector{Bool}  : indicates whether the row is a duplicate of some   prior row   See also  unique  and  unique! .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df   =   vcat ( df ,   df )  nonunique ( df )   # DataFrames.rename     Function .   Rename columns  rename! ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename! ( df :: AbstractDataFrame ,   d :: Associative )  rename! ( f :: Function ,   df :: AbstractDataFrame )  rename ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename ( f :: Function ,   df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame  d  : an Associative type that maps the original name to a new name  f  : a function that has the old column name (a symbol) as input   and new column name (a symbol) as output   Result   ::AbstractDataFrame  : the updated result   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  rename ( x   -   symbol ( uppercase ( string ( x ))),   df )  rename ( df ,   @ compat ( Dict (: i = : A ,   : x = : X )))  rename ( df ,   : y ,   : Y )  rename! ( df ,   @ compat ( Dict (: i = : A ,   : x = : X )))   # DataFrames.rename!     Function .   Rename columns  rename! ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename! ( df :: AbstractDataFrame ,   d :: Associative )  rename! ( f :: Function ,   df :: AbstractDataFrame )  rename ( df :: AbstractDataFrame ,   from :: Symbol ,   to :: Symbol )  rename ( f :: Function ,   df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame  d  : an Associative type that maps the original name to a new name  f  : a function that has the old column name (a symbol) as input   and new column name (a symbol) as output   Result   ::AbstractDataFrame  : the updated result   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  rename ( x   -   symbol ( uppercase ( string ( x ))),   df )  rename ( df ,   @ compat ( Dict (: i = : A ,   : x = : X )))  rename ( df ,   : y ,   : Y )  rename! ( df ,   @ compat ( Dict (: i = : A ,   : x = : X )))   # DataArrays.tail     Function .   Show the first or last part of an AbstractDataFrame  head ( df :: AbstractDataFrame ,   r :: Int   =   6 )  tail ( df :: AbstractDataFrame ,   r :: Int   =   6 )   Arguments   df  : the AbstractDataFrame  r  : the number of rows to show   Result   ::AbstractDataFrame  : the first or last part of  df   Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  head ( df )  tail ( df )   # Base.unique     Function .   Delete duplicate rows  unique ( df :: AbstractDataFrame )  unique! ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::AbstractDataFrame  : the updated version   See also  nonunique .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df   =   vcat ( df ,   df )  unique ( df )     # doesn t modify df  unique! ( df )    # modifies df   # DataFrames.unique!     Function .   Delete duplicate rows  unique ( df :: AbstractDataFrame )  unique! ( df :: AbstractDataFrame )   Arguments   df  : the AbstractDataFrame   Result   ::AbstractDataFrame  : the updated version   See also  nonunique .  Examples  df   =   DataFrame ( i   =   1 : 10 ,   x   =   rand ( 10 ),   y   =   rand ([ a ,   b ,   c ],   10 ))  df   =   vcat ( df ,   df )  unique ( df )     # doesn t modify df  unique! ( df )    # modifies df", 
            "title": "Utilities"
        }, 
        {
            "location": "/lib/manipulation/", 
            "text": "Data Manipulation\n\n\n\n\njoin\n\n\nmelt\n\n\nmeltdf\n\n\nstack\n\n\nstackdf\n\n\nunstack\n\n\n\n\n\n\nJoins\n\n\n#\nBase.join\n \n \nFunction\n.\n\n\n\n\nJoin two DataFrames\n\n\njoin\n(\ndf1\n::\nAbstractDataFrame\n,\n\n     \ndf2\n::\nAbstractDataFrame\n;\n\n     \non\n::\nUnion\n{\nSymbol\n,\n \nVector\n{\nSymbol\n}}\n \n=\n \nSymbol\n[],\n\n     \nkind\n::\nSymbol\n \n=\n \n:\ninner\n)\n\n\n\n\n\n\nArguments\n\n\n\n\ndf1\n, \ndf2\n : the two AbstractDataFrames to be joined\n\n\n\n\nKeyword Arguments\n\n\n\n\n\n\non\n : a Symbol or Vector{Symbol}, the column(s) used as keys when   joining; required argument except for \nkind = :cross\n\n\n\n\n\n\nkind\n : the type of join, options include:\n\n\n\n\n\n\n:inner\n : only include rows with keys that match in both \ndf1\n     and \ndf2\n, the default\n\n\n\n\n:outer\n : include all rows from \ndf1\n and \ndf2\n\n\n:left\n : include all rows from \ndf1\n\n\n:right\n : include all rows from \ndf2\n\n\n:semi\n : return rows of \ndf1\n that match with the keys in \ndf2\n\n\n:anti\n : return rows of \ndf1\n that do not match with the keys in \ndf2\n\n\n:cross\n : a full Cartesian product of the key combinations; every     row of \ndf1\n is matched with every row of \ndf2\n\n\n\n\nNA\ns are filled in where needed to complete joins.\n\n\nResult\n\n\n\n\n::DataFrame\n : the joined DataFrame \n\n\n\n\nExamples\n\n\nname\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n,\n \n3\n],\n \nName\n \n=\n \n[\nJohn Doe\n,\n \nJane Doe\n,\n \nJoe Blogs\n])\n\n\njob\n \n=\n \nDataFrame\n(\nID\n \n=\n \n[\n1\n,\n \n2\n,\n \n4\n],\n \nJob\n \n=\n \n[\nLawyer\n,\n \nDoctor\n,\n \nFarmer\n])\n\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nouter\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nleft\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nright\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nsemi\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \non\n \n=\n \n:\nID\n,\n \nkind\n \n=\n \n:\nanti\n)\n\n\njoin\n(\nname\n,\n \njob\n,\n \nkind\n \n=\n \n:\ncross\n)\n\n\n\n\n\n\n\n\nReshaping\n\n\n#\nDataFrames.melt\n \n \nFunction\n.\n\n\n\n\nStacks a DataFrame; convert from a wide to long format; see \nstack\n.\n\n\n#\nDataFrames.stack\n \n \nFunction\n.\n\n\n\n\nStacks a DataFrame; convert from a wide to long format\n\n\nstack\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n,\n \nid_vars\n)\n\n\nstack\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n)\n\n\nstack\n(\ndf\n::\nAbstractDataFrame\n)\n\n\nmelt\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n,\n \nmeasure_vars\n)\n\n\nmelt\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n)\n\n\n\n\n\n\nArguments\n\n\n\n\n\n\ndf\n : the AbstractDataFrame to be stacked\n\n\n\n\n\n\nmeasure_vars\n : the columns to be stacked (the measurement   variables), a normal column indexing type, like a Symbol,   Vector{Symbol}, Int, etc.; for \nmelt\n, defaults to all   variables that are not \nid_vars\n\n\n\n\n\n\nid_vars\n : the identifier columns that are repeated during   stacking, a normal column indexing type; for \nstack\n defaults to all   variables that are not \nmeasure_vars\n\n\n\n\n\n\nIf neither \nmeasure_vars\n or \nid_vars\n are given, \nmeasure_vars\n defaults to all floating point columns.\n\n\nResult\n\n\n\n\n::DataFrame\n : the long-format dataframe with column \n:value\n   holding the values of the stacked columns (\nmeasure_vars\n), with   column \n:variable\n a Vector of Symbols with the \nmeasure_vars\n name,   and with columns for each of the \nid_vars\n.\n\n\n\n\nSee also \nstackdf\n and \nmeltdf\n for stacking methods that return a view into the original DataFrame. See \nunstack\n for converting from long to wide format.\n\n\nExamples\n\n\nd1\n \n=\n \nDataFrame\n(\na\n \n=\n \nrepeat\n([\n1\n:\n3\n;],\n \ninner\n \n=\n \n[\n4\n]),\n\n               \nb\n \n=\n \nrepeat\n([\n1\n:\n4\n;],\n \ninner\n \n=\n \n[\n3\n]),\n\n               \nc\n \n=\n \nrandn\n(\n12\n),\n\n               \nd\n \n=\n \nrandn\n(\n12\n),\n\n               \ne\n \n=\n \nmap\n(\nstring\n,\n \na\n:\nl\n))\n\n\n\nd1s\n \n=\n \nstack\n(\nd1\n,\n \n[:\nc\n,\n \n:\nd\n])\n\n\nd1s2\n \n=\n \nstack\n(\nd1\n,\n \n[:\nc\n,\n \n:\nd\n],\n \n[:\na\n])\n\n\nd1m\n \n=\n \nmelt\n(\nd1\n,\n \n[:\na\n,\n \n:\nb\n,\n \n:\ne\n])\n\n\n\n\n\n\n#\nDataFrames.unstack\n \n \nFunction\n.\n\n\n\n\nUnstacks a DataFrame; convert from a long to wide format\n\n\nunstack\n(\ndf\n::\nAbstractDataFrame\n,\n \nrowkey\n,\n \ncolkey\n,\n \nvalue\n)\n\n\nunstack\n(\ndf\n::\nAbstractDataFrame\n,\n \ncolkey\n,\n \nvalue\n)\n\n\nunstack\n(\ndf\n::\nAbstractDataFrame\n)\n\n\n\n\n\n\nArguments\n\n\n\n\n\n\ndf\n : the AbstractDataFrame to be unstacked\n\n\n\n\n\n\nrowkey\n : the column with a unique key for each row, if not given,   find a key by grouping on anything not a \ncolkey\n or \nvalue\n\n\n\n\n\n\ncolkey\n : the column holding the column names in wide format,   defaults to \n:variable\n\n\n\n\n\n\nvalue\n : the value column, defaults to \n:value\n\n\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n : the wide-format dataframe\n\n\n\n\nExamples\n\n\nwide\n \n=\n \nDataFrame\n(\nid\n \n=\n \n1\n:\n12\n,\n\n                 \na\n  \n=\n \nrepeat\n([\n1\n:\n3\n;],\n \ninner\n \n=\n \n[\n4\n]),\n\n                 \nb\n  \n=\n \nrepeat\n([\n1\n:\n4\n;],\n \ninner\n \n=\n \n[\n3\n]),\n\n                 \nc\n  \n=\n \nrandn\n(\n12\n),\n\n                 \nd\n  \n=\n \nrandn\n(\n12\n))\n\n\n\nlong\n \n=\n \nstack\n(\nwide\n)\n\n\nwide0\n \n=\n \nunstack\n(\nlong\n)\n\n\nwide1\n \n=\n \nunstack\n(\nlong\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\nwide2\n \n=\n \nunstack\n(\nlong\n,\n \n:\nid\n,\n \n:\nvariable\n,\n \n:\nvalue\n)\n\n\n\n\n\n\nNote that there are some differences between the widened results above.\n\n\n#\nDataFrames.stackdf\n \n \nFunction\n.\n\n\n\n\nA stacked view of a DataFrame (long format)\n\n\nLike \nstack\n and \nmelt\n, but a view is returned rather than data copies.\n\n\nstackdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n,\n \nid_vars\n)\n\n\nstackdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nmeasure_vars\n)\n\n\nmeltdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n,\n \nmeasure_vars\n)\n\n\nmeltdf\n(\ndf\n::\nAbstractDataFrame\n,\n \nid_vars\n)\n\n\n\n\n\n\nArguments\n\n\n\n\n\n\ndf\n : the wide AbstractDataFrame\n\n\n\n\n\n\nmeasure_vars\n : the columns to be stacked (the measurement   variables), a normal column indexing type, like a Symbol,   Vector{Symbol}, Int, etc.; for \nmelt\n, defaults to all   variables that are not \nid_vars\n\n\n\n\n\n\nid_vars\n : the identifier columns that are repeated during   stacking, a normal column indexing type; for \nstack\n defaults to all   variables that are not \nmeasure_vars\n\n\n\n\n\n\nResult\n\n\n\n\n::DataFrame\n : the long-format dataframe with column \n:value\n   holding the values of the stacked columns (\nmeasure_vars\n), with   column \n:variable\n a Vector of Symbols with the \nmeasure_vars\n name,   and with columns for each of the \nid_vars\n.\n\n\n\n\nThe result is a view because the columns are special AbstractVectors that return indexed views into the original DataFrame.\n\n\nExamples\n\n\nd1\n \n=\n \nDataFrame\n(\na\n \n=\n \nrepeat\n([\n1\n:\n3\n;],\n \ninner\n \n=\n \n[\n4\n]),\n\n               \nb\n \n=\n \nrepeat\n([\n1\n:\n4\n;],\n \ninner\n \n=\n \n[\n3\n]),\n\n               \nc\n \n=\n \nrandn\n(\n12\n),\n\n               \nd\n \n=\n \nrandn\n(\n12\n),\n\n               \ne\n \n=\n \nmap\n(\nstring\n,\n \na\n:\nl\n))\n\n\n\nd1s\n \n=\n \nstackdf\n(\nd1\n,\n \n[:\nc\n,\n \n:\nd\n])\n\n\nd1s2\n \n=\n \nstackdf\n(\nd1\n,\n \n[:\nc\n,\n \n:\nd\n],\n \n[:\na\n])\n\n\nd1m\n \n=\n \nmeltdf\n(\nd1\n,\n \n[:\na\n,\n \n:\nb\n,\n \n:\ne\n])\n\n\n\n\n\n\n#\nDataFrames.meltdf\n \n \nFunction\n.\n\n\n\n\nA stacked view of a DataFrame (long format); see \nstackdf", 
            "title": "Data manipulation"
        }, 
        {
            "location": "/lib/manipulation/#data-manipulation", 
            "text": "join  melt  meltdf  stack  stackdf  unstack", 
            "title": "Data Manipulation"
        }, 
        {
            "location": "/lib/manipulation/#joins", 
            "text": "# Base.join     Function .   Join two DataFrames  join ( df1 :: AbstractDataFrame , \n      df2 :: AbstractDataFrame ; \n      on :: Union { Symbol ,   Vector { Symbol }}   =   Symbol [], \n      kind :: Symbol   =   : inner )", 
            "title": "Joins"
        }, 
        {
            "location": "/lib/manipulation/#arguments", 
            "text": "df1 ,  df2  : the two AbstractDataFrames to be joined", 
            "title": "Arguments"
        }, 
        {
            "location": "/lib/manipulation/#keyword-arguments", 
            "text": "on  : a Symbol or Vector{Symbol}, the column(s) used as keys when   joining; required argument except for  kind = :cross    kind  : the type of join, options include:    :inner  : only include rows with keys that match in both  df1      and  df2 , the default   :outer  : include all rows from  df1  and  df2  :left  : include all rows from  df1  :right  : include all rows from  df2  :semi  : return rows of  df1  that match with the keys in  df2  :anti  : return rows of  df1  that do not match with the keys in  df2  :cross  : a full Cartesian product of the key combinations; every     row of  df1  is matched with every row of  df2   NA s are filled in where needed to complete joins.", 
            "title": "Keyword Arguments"
        }, 
        {
            "location": "/lib/manipulation/#result", 
            "text": "::DataFrame  : the joined DataFrame", 
            "title": "Result"
        }, 
        {
            "location": "/lib/manipulation/#examples", 
            "text": "name   =   DataFrame ( ID   =   [ 1 ,   2 ,   3 ],   Name   =   [ John Doe ,   Jane Doe ,   Joe Blogs ])  job   =   DataFrame ( ID   =   [ 1 ,   2 ,   4 ],   Job   =   [ Lawyer ,   Doctor ,   Farmer ])  join ( name ,   job ,   on   =   : ID )  join ( name ,   job ,   on   =   : ID ,   kind   =   : outer )  join ( name ,   job ,   on   =   : ID ,   kind   =   : left )  join ( name ,   job ,   on   =   : ID ,   kind   =   : right )  join ( name ,   job ,   on   =   : ID ,   kind   =   : semi )  join ( name ,   job ,   on   =   : ID ,   kind   =   : anti )  join ( name ,   job ,   kind   =   : cross )", 
            "title": "Examples"
        }, 
        {
            "location": "/lib/manipulation/#reshaping", 
            "text": "# DataFrames.melt     Function .   Stacks a DataFrame; convert from a wide to long format; see  stack .  # DataFrames.stack     Function .   Stacks a DataFrame; convert from a wide to long format  stack ( df :: AbstractDataFrame ,   measure_vars ,   id_vars )  stack ( df :: AbstractDataFrame ,   measure_vars )  stack ( df :: AbstractDataFrame )  melt ( df :: AbstractDataFrame ,   id_vars ,   measure_vars )  melt ( df :: AbstractDataFrame ,   id_vars )", 
            "title": "Reshaping"
        }, 
        {
            "location": "/lib/manipulation/#arguments_1", 
            "text": "df  : the AbstractDataFrame to be stacked    measure_vars  : the columns to be stacked (the measurement   variables), a normal column indexing type, like a Symbol,   Vector{Symbol}, Int, etc.; for  melt , defaults to all   variables that are not  id_vars    id_vars  : the identifier columns that are repeated during   stacking, a normal column indexing type; for  stack  defaults to all   variables that are not  measure_vars    If neither  measure_vars  or  id_vars  are given,  measure_vars  defaults to all floating point columns.", 
            "title": "Arguments"
        }, 
        {
            "location": "/lib/manipulation/#result_1", 
            "text": "::DataFrame  : the long-format dataframe with column  :value    holding the values of the stacked columns ( measure_vars ), with   column  :variable  a Vector of Symbols with the  measure_vars  name,   and with columns for each of the  id_vars .   See also  stackdf  and  meltdf  for stacking methods that return a view into the original DataFrame. See  unstack  for converting from long to wide format.", 
            "title": "Result"
        }, 
        {
            "location": "/lib/manipulation/#examples_1", 
            "text": "d1   =   DataFrame ( a   =   repeat ([ 1 : 3 ;],   inner   =   [ 4 ]), \n                b   =   repeat ([ 1 : 4 ;],   inner   =   [ 3 ]), \n                c   =   randn ( 12 ), \n                d   =   randn ( 12 ), \n                e   =   map ( string ,   a : l ))  d1s   =   stack ( d1 ,   [: c ,   : d ])  d1s2   =   stack ( d1 ,   [: c ,   : d ],   [: a ])  d1m   =   melt ( d1 ,   [: a ,   : b ,   : e ])   # DataFrames.unstack     Function .   Unstacks a DataFrame; convert from a long to wide format  unstack ( df :: AbstractDataFrame ,   rowkey ,   colkey ,   value )  unstack ( df :: AbstractDataFrame ,   colkey ,   value )  unstack ( df :: AbstractDataFrame )", 
            "title": "Examples"
        }, 
        {
            "location": "/lib/manipulation/#arguments_2", 
            "text": "df  : the AbstractDataFrame to be unstacked    rowkey  : the column with a unique key for each row, if not given,   find a key by grouping on anything not a  colkey  or  value    colkey  : the column holding the column names in wide format,   defaults to  :variable    value  : the value column, defaults to  :value", 
            "title": "Arguments"
        }, 
        {
            "location": "/lib/manipulation/#result_2", 
            "text": "::DataFrame  : the wide-format dataframe", 
            "title": "Result"
        }, 
        {
            "location": "/lib/manipulation/#examples_2", 
            "text": "wide   =   DataFrame ( id   =   1 : 12 , \n                  a    =   repeat ([ 1 : 3 ;],   inner   =   [ 4 ]), \n                  b    =   repeat ([ 1 : 4 ;],   inner   =   [ 3 ]), \n                  c    =   randn ( 12 ), \n                  d    =   randn ( 12 ))  long   =   stack ( wide )  wide0   =   unstack ( long )  wide1   =   unstack ( long ,   : variable ,   : value )  wide2   =   unstack ( long ,   : id ,   : variable ,   : value )   Note that there are some differences between the widened results above.  # DataFrames.stackdf     Function .   A stacked view of a DataFrame (long format)  Like  stack  and  melt , but a view is returned rather than data copies.  stackdf ( df :: AbstractDataFrame ,   measure_vars ,   id_vars )  stackdf ( df :: AbstractDataFrame ,   measure_vars )  meltdf ( df :: AbstractDataFrame ,   id_vars ,   measure_vars )  meltdf ( df :: AbstractDataFrame ,   id_vars )", 
            "title": "Examples"
        }, 
        {
            "location": "/lib/manipulation/#arguments_3", 
            "text": "df  : the wide AbstractDataFrame    measure_vars  : the columns to be stacked (the measurement   variables), a normal column indexing type, like a Symbol,   Vector{Symbol}, Int, etc.; for  melt , defaults to all   variables that are not  id_vars    id_vars  : the identifier columns that are repeated during   stacking, a normal column indexing type; for  stack  defaults to all   variables that are not  measure_vars", 
            "title": "Arguments"
        }, 
        {
            "location": "/lib/manipulation/#result_3", 
            "text": "::DataFrame  : the long-format dataframe with column  :value    holding the values of the stacked columns ( measure_vars ), with   column  :variable  a Vector of Symbols with the  measure_vars  name,   and with columns for each of the  id_vars .   The result is a view because the columns are special AbstractVectors that return indexed views into the original DataFrame.", 
            "title": "Result"
        }, 
        {
            "location": "/lib/manipulation/#examples_3", 
            "text": "d1   =   DataFrame ( a   =   repeat ([ 1 : 3 ;],   inner   =   [ 4 ]), \n                b   =   repeat ([ 1 : 4 ;],   inner   =   [ 3 ]), \n                c   =   randn ( 12 ), \n                d   =   randn ( 12 ), \n                e   =   map ( string ,   a : l ))  d1s   =   stackdf ( d1 ,   [: c ,   : d ])  d1s2   =   stackdf ( d1 ,   [: c ,   : d ],   [: a ])  d1m   =   meltdf ( d1 ,   [: a ,   : b ,   : e ])   # DataFrames.meltdf     Function .   A stacked view of a DataFrame (long format); see  stackdf", 
            "title": "Examples"
        }, 
        {
            "location": "/NEWS/", 
            "text": "../../NEWS.md", 
            "title": "Release notes"
        }, 
        {
            "location": "/LICENSE/", 
            "text": "../../LICENSE.md", 
            "title": "License"
        }
    ]
}